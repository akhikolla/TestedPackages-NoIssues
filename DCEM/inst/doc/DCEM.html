<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />



<title>DCEM</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>





<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">DCEM</h1>



<div id="package-overview" class="section level2">
<h2>Package Overview</h2>
<p>Implements the Expectation Maximisation Algorithm for clustering the multivariate and univariate datasets. There are two versions of EM implemented-EM* (converge faster by avoiding revisiting the data) and EM. For more details on EM*, see the ‘References’ section below.</p>
<p>The package has been tested with both real and simulated datasets. The package comes bundled with a dataset for demonstration (ionosphere_data.csv). More help about the package can be seen by typing <code>?DCEM</code> in the R console (after installing the package).</p>
<p><strong>Currently, data imputation is not supported and user has to handle the missing data before using the package.</strong></p>
</div>
<div id="contact" class="section level2">
<h2>Contact</h2>
<div id="for-reporting-issues" class="section level3">
<h3>For Reporting Issues</h3>
<p><a href="https://github.com/parichit/DCEM/issues">Issues</a></p>
</div>
<div id="github-repository-link" class="section level3">
<h3>GitHub Repository Link</h3>
<p><a href="https://github.com/parichit/DCEM">Github Repository</a></p>
</div>
</div>
<div id="installation-instructions" class="section level2">
<h2>Installation Instructions</h2>
<p><strong>Dependencies</strong> First, install all the required packages as follows:</p>
<p>install.packages(c(“matrixcalc”, “mvtnorm”, “MASS”, “Rcpp”))</p>
<div id="installing-from-cran" class="section level3">
<h3>Installing from CRAN</h3>
<p>Use install.packages() in the R console as follow:</p>
<pre><code>install.packages(&quot;DCEM&quot;)</code></pre>
<p><strong><em>Installing from the Source Package</em></strong></p>
<p>Download the source tar ball for DCEM from <a href="https://github.com/parichit/DCEM/releases">Github</a> and install as follows:</p>
<pre><code>R CMD install DCEM_2.0.3.tar.gz</code></pre>
</div>
</div>
<div id="quick-start" class="section level2">
<h2>Quick Start</h2>
<ul>
<li><p>For demonstration purpose, use the <code>dcem_test()</code> function from the R console. This function invokes the dcem_star_train() on the bundeled <code>ionosphere_data</code>.</p></li>
<li><p>The function <code>dcem_test()</code> returns a list containing the output i.e., posterior probabilities, meu, sigma, prior and cluster membership for data. The parameters can be accessed as follows where <code>sample_out</code> is the list containing the output:</p></li>
</ul>
<div id="call-the-dcem_test" class="section level3">
<h3>Call the dcem_test()</h3>
<pre><code>library(&quot;DCEM&quot;)
sample_out = dcem_test()</code></pre>
</div>
<div id="access-the-output" class="section level3">
<h3>Access the output</h3>
<ol style="list-style-type: decimal">
<li><p><code>sample_out$prob</code>: A matrix of posterior-probabilities</p></li>
<li><p><code>sample_out$meu</code>: A matrix of cluster centers.</p></li>
<li><p>`<code>sample_out$sigma</code></p>
<ul>
<li><p>For multivariate data: List of co-variance matrices for the Gaussian(s).</p></li>
<li><p>For univariate data: Vector of standard deviation for the Gaussian(s))</p></li>
</ul></li>
<li><p><code>sample_out$prior</code>: A vector of prior.</p></li>
<li><p><code>sample_out4membership</code>: A vector of cluster membership for data.</p></li>
</ol>
</div>
<div id="use-em-improved-em-algorithm-to-cluster-the-ionosphere-data" class="section level3">
<h3>Use EM* (improved EM algorithm) to cluster the Ionosphere data</h3>
<p>DCEM comes bundeled with the Ionosphere data. The example below shows how to use EM* for clustering this data set.</p>
<pre><code># Make sure you have imported the package.
library(&quot;DCEM&quot;)

# Set the file path
data_file =  file.path(trimws(getwd()), &quot;data&quot;, &quot;ionosphere_data.csv&quot;)

# Reading the input file into a dataframe.
ionosphere_data = read.csv2(
    file = data_file,
    sep = &quot;,&quot;,
    header = FALSE,
    stringsAsFactors = FALSE
  )
  
# Cleaning the data by removing the 35th and 2nd column as they contain the 
# labels and 0&#39;s respectively.
ionosphere_data =  trim_data(&quot;2, 35&quot;, ionosphere_data)
 
 
# Call the dcem_star_train() function on the cleaned data.
sample_out = dcem_star_train(ionosphere_data) </code></pre>
</div>
<div id="use-em-t-original-em-algorithm-to-cluster-the-ionosphere-data" class="section level3">
<h3>Use EM-T (original EM algorithm) to cluster the Ionosphere data</h3>
<p>The example below shows how to use EM-T for clustering the Ionosphere data set.</p>
<pre><code># Make sure you have imported the package.
library(&quot;DCEM&quot;)

# Set the file path
data_file =  file.path(trimws(getwd()), &quot;data&quot;, &quot;ionosphere_data.csv&quot;)

# Reading the input file into a dataframe.
ionosphere_data = read.csv2(
    file = data_file,
    sep = &quot;,&quot;,
    header = FALSE,
    stringsAsFactors = FALSE
  )
  
# Cleaning the data by removing the 35th and 2nd column as they contain the 
# labels and 0&#39;s respectively.
ionosphere_data =  trim_data(&quot;2, 35&quot;, ionosphere_data)
 
 
# Call the dcem_star_train() function on the cleaned data.
sample_out = dcem_train(ionosphere_data) </code></pre>
</div>
<div id="parameters-in-the-function-call" class="section level3">
<h3>Parameters in the function call:</h3>
<p>Both dcem_star_train() and dcem_train() calls share the same parameters except the argument ‘threshold’ which is only present in dcem_train(). This is because for EM*, threshold is empirically found to not affect the clustering results significantly. The function arguments are described below:</p>
<p><strong>* data (dataframe)</strong>: Dataframe containing the user specified data.</p>
<p><strong>* threshold (decimal)</strong>: Convergence threshold (if meu are within this threshold then the algorithm stops and exit (default = 0.0001).</p>
<p><strong>* iteration_count (numeric)</strong>: Number of iterations for which the algorithm should run, if the convergence is not achieved then the algorithm stops and exit (default = 200).</p>
<p><strong>* num_clusters (numeric)</strong>: The number of clusters (default = 2).</p>
<p><strong>* seed_meu (matrix)</strong>: User specified set of meu to be used as initial centers (default = None).</p>
<p><strong>* seeding (string)</strong>: The initialization scheme (choices = ‘rand’ or ‘improved’, default = rand).</p>
</div>
</div>
<div id="initialization-schemes" class="section level2">
<h2>Initialization schemes</h2>
<p>In case of iterative clustering algorithm like EM, choice of initial cluster centers can affect the rate of convergence in terms of execution time and number of iterations. Therefore, DCEM allows the users to choose from the following initialization schemes according to their requirement.</p>
<ol style="list-style-type: decimal">
<li><strong>Random initialization</strong>: This is the (default) choice for both EM-T and EM* procedures. Cluster centers are selected by randomly sampling from the input data. It is fast, though it may not result in the best performance i.e., selected centers may result in the algorithm taking more iterations hence longer execution time. The following code illustrate how to use random initialization explicitly.</li>
</ol>
<p>Set the seed and create a mixture of gaussians.</p>
<pre><code>R&gt; set.seed(49)
R&gt; sample_uv_data = as.data.frame(c(rnorm(500, 5, 0.5), rnorm(1000, 20, 1), 
+ rnorm(100, 31, 2)))</code></pre>
<p>Randomly shuffle the data, set the seed and call the dcem_train() function.</p>
<pre><code>R&gt; sample_uv_data = as.data.frame(sample_uv_data[sample(nrow(sample_uv_data)),])
R&gt; set.seed(21)
R&gt; sample_uv_out = dcem_train(sample_uv_data, num_clusters = 3, 
+ iteration_count = 100, threshold = 0.0001, seeding = &quot;rand&quot;)</code></pre>
<p>Note: The run with random initialization took 14 iterations to converge.</p>
<pre><code>[1] &quot;Specified threshold =  1e-04&quot;
[1] &quot;Specified iterations =  100&quot;
[1] &quot;Specified number of  clusters =  3&quot;
[1] &quot;Using the improved Kmeans++ initialization scheme.&quot;
[1] &quot;Convergence at iteration number:  14&quot;</code></pre>
<ol style="list-style-type: decimal">
<li><strong>Improved initialization</strong>: This approach utilizes an advanced initialization procedure based on the k++ technique. It was originally proposed to improve the initialization of the K-means algorithm. When compared to the random initialization, this method has been empirically shown to improve both the speed and accuracy. It can be used as follows.</li>
</ol>
<p>Use the same seed and call the dcem_train() function with seeding set to ‘improved’.</p>
<pre><code>R&gt; set.seed(21)
R&gt; sample_uv_out = dcem_train(sample_uv_data, num_clusters = 3, 
+ iteration_count = 100, threshold = 0.0001, seeding = &quot;improved&quot;)</code></pre>
<p>Note: The run with improved initialization took 9 iterations to converge.</p>
<pre><code>[1] &quot;Specified threshold =  1e-04&quot;
[1] &quot;Specified iterations =  100&quot;
[1] &quot;Specified number of  clusters =  3&quot;
[1] &quot;Using the improved Kmeans++ initialization scheme.&quot;
[1] &quot;Convergence at iteration number:  9&quot;</code></pre>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
