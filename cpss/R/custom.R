EST <- function(dataset, n, g_subdat, g_param, g_cost, algorithm, dist_min, ncps_max, pelt_pen_val, pelt_K, wbs_nintervals, model, g_smry, easy_cost, param.opt) {

  if (is.null(g_smry)) {

    if (algorithm == "SN") {
      res <- SN_custom_naive_R(dataset, n, g_subdat, g_param, g_cost, ncps_max, dist_min, param.opt)$cpt_cand
    } else if (algorithm == "BS") {
      res <- BS_custom_naive_R(dataset, n, g_subdat, g_param, g_cost, ncps_max, dist_min, param.opt)$cpt_cand
    } else if (algorithm == "WBS") {
      lr_M <- matrix(NA, wbs_nintervals, 2)
      for (i in 1:wbs_nintervals) {
        lr_M[i, ] <- sort(sample(0:n, 2, replace = FALSE))
      }
      res <- WBS_custom_naive_R(dataset, n, g_subdat, g_param, g_cost, ncps_max, dist_min, lr_M, param.opt)$cpt_cand
    } else if (algorithm == "PELT") {
      res <- PELT_custom_naive_R(dataset, n, g_subdat, g_param, g_cost, pelt_pen_val, dist_min, pelt_K, param.opt)$cpt_cand
      temp_n_row <- length(res[res[, 1] > 0, 1])
      res <- res[1:temp_n_row, ]
    } else {
      stop("Not supported searching algorithm!")
    }

  } else {

    dat_smry <- g_smry(dataset, param.opt)

    if (is.null(easy_cost)) {

      if (algorithm == "SN") {
        res <- SN(dat_smry, n, ncps_max, dist_min, model)$cpt_cand
      } else if (algorithm == "BS") {
        res <- BS(dat_smry, n, ncps_max, dist_min, model)$cpt_cand
      } else if (algorithm == "WBS") {
        lr_M <- matrix(NA, wbs_nintervals, 2)
        for (i in 1:wbs_nintervals) {
          lr_M[i, ] <- sort(sample(0:n, 2, replace = FALSE))
        }
        res <- WBS(dat_smry, n, ncps_max, dist_min, lr_M, model)$cpt_cand
      } else if (algorithm == "PELT") {
        res <- PELT(dat_smry, n, pelt_pen_val, dist_min, pelt_K, model)$cpt_cand
        temp_n_row <- length(res[res[, 1] > 0, 1])
        res <- res[1:temp_n_row, ]
      } else {
        stop("Not supported searching algorithm!")
      }

    } else {

      if (algorithm == "SN") {
        res <- SN_custom_R(dat_smry, n, ncps_max, dist_min, easy_cost)$cpt_cand
      } else if (algorithm == "BS") {
        res <- BS_custom_R(dat_smry, n, ncps_max, dist_min, easy_cost)$cpt_cand
      } else if (algorithm == "WBS") {
        lr_M <- matrix(NA, wbs_nintervals, 2)
        for (i in 1:wbs_nintervals) {
          lr_M[i, ] <- sort(sample(0:n, 2, replace = FALSE))
        }
        res <- WBS_custom_R(dat_smry, n, ncps_max, dist_min, lr_M, easy_cost)$cpt_cand
      } else if (algorithm == "PELT") {
        res <- PELT_custom_R(dat_smry, n, pelt_pen_val, dist_min, pelt_K, easy_cost)$cpt_cand
        temp_n_row <- length(res[res[, 1] > 0, 1])
        res <- res[1:temp_n_row, ]
      } else {
        stop("Not supported searching algorithm!")
      }

    }

  }

  if (algorithm == "PELT") {
    res <- matrix(res, temp_n_row, length(pelt_pen_val))
  }

  if (algorithm == "SN") {
    idx <- !apply(is.na(res), 1, all)
    res <- matrix(res[idx, ], sum(idx), ncps_max)
  }
  return(res)
}

#' @importFrom stats approx
COPS <- function(dataset, n, indices, g_subdat, g_param, g_cost, algorithm, dist_min, ncps_max, pelt_pen_val, pelt_K, wbs_nintervals, model, g_smry, easy_cost, param.opt) {

  res <- list()
  subdat <- g_subdat(dataset, indices)
  n_subdat <- sum(indices)
  dist_min_subdata <- max(floor(dist_min / 2), 1)
  res_est <- EST(subdat, n_subdat, g_subdat, g_param, g_cost, algorithm, dist_min_subdata, ncps_max, pelt_pen_val, pelt_K, wbs_nintervals, model, g_smry, easy_cost, param.opt)
  cost_val <- rep(NA, ncps_max)
  if (algorithm %in% c("SN", "BS", "WBS")) {
    ncps_max1 <- nrow(res_est)
    for (k in 1:ncps_max1) {
      cps_k_subdat <- sort(res_est[k, k:1])
      cps_k <- (1:n)[indices][cps_k_subdat]
      ID <- rep(1:(k + 1), c(cps_k, n) - c(0, cps_k))
      cost_val_k_cum <- 0
      for (j in 1:(k + 1)) {
        subdat_kj <- g_subdat(dataset, ID == j & indices)
        param_kj <- g_param(subdat_kj, param.opt)
        subdat_val_kj <- g_subdat(dataset, ID == j & (!indices))
        cost_val_k_cum <- cost_val_k_cum + g_cost(subdat_val_kj, param_kj)
      }
      cost_val[k] <- cost_val_k_cum
    }
  } else if (algorithm == "PELT") {
    pelt_ncps <- rep(NA, length(pelt_pen_val))
    pelt_cost <- rep(NA, length(pelt_pen_val))
    for (k in 1:length(pelt_pen_val)) {
      cps_k_subdat <- res_est[res_est[, k] > 0, k]
      if (length(cps_k_subdat) == 0) {
        stop(paste0("No change point is detected as the value of penalty ", pelt_pen_val[k], " is too large!"))
      }
      cps_k_subdat <- cps_k_subdat[length(cps_k_subdat):1]
      cps_k <- (1:n)[indices][cps_k_subdat]
      pelt_ncps[k] <- length(cps_k)
      ID <- rep(1:(pelt_ncps[k] + 1), c(cps_k, n) - c(0, cps_k))
      pelt_cost_k_cum <- 0
      for (j in 1:(pelt_ncps[k] + 1)) {
        subdat_kj <- g_subdat(dataset, ID == j & indices)
        param_kj <- g_param(subdat_kj, param.opt)
        subdat_val_kj <- g_subdat(dataset, ID == j & (!indices))
        pelt_cost_k_cum <- pelt_cost_k_cum + g_cost(subdat_val_kj, param_kj)
      }
      pelt_cost[k] <- pelt_cost_k_cum
    }
    ans <- unique(cbind(pelt_ncps, pelt_cost))
    ans <- ans[ans[, 1] <= ncps_max, ]
    n_unique <- nrow(ans)
    if (is.null(n_unique)) {
      stop("The values of the penalty may yield the same change-points!")
    }
    ans <- matrix(ans, n_unique, 2)
    if (n_unique >= 2) {
      cost_val <- approx(ans[, 1], ans[, 2], 1:ncps_max, method = "linear")$y
    } else {
      stop("The values of the penalty may yield the same change-points!")
    }
  } else {
    stop("Not supported searching algorithm!")
  }
  res$cost_val <- cost_val
  return(res)
}

#' Detecting changes in uers-customized models
#'
#' @param dataset an \code{ANY} object that could be of any form such as a vector, matrix, tensor, list, etc.
#' @param n an integer indicating the sample size of the \code{dataset}.
#' @param g_subdat a customized R function of two arguments \code{dat} and \code{indices}, that returns a subset of the \code{dat} (inheriting the class from that of \code{dataset}) according to given indices along the observed time orders. The argument \code{indices} is a logical vector with \code{TRUE} indicating selected indices.
#' @param param.opt an \code{ANY} object that could be of any form, specifying additional global constant parameters beyond the interested parameters.
#' @param g_param a customized R function of two arguments, \code{dat} and \code{param.opt}, that returns estimates of interested parameters that minimizes users-specified cost for a data set \code{dat}. The returned object could be of any class such as a numeric value, vector, matrix, list, etc. The argument \code{param.opt} might be used in the estimation procedures.
#' @param g_cost a customized R function of two arguments, \code{dat} and \code{param}, that returns a numeric value of associated cost for a data set \code{dat}, under the knowledge of the interested parameters being \code{param}. The argument \code{param} inherits from the class of the returned object of the function \code{g_param}. If \code{param.opt} is needed to evaluate the cost, they should be packed into \code{param} when defining the function \code{g_param}.
#' @param algorithm a character string specifying the change-point searching algorithm, one of four state-of-the-art candidates "SN" (segment neighborhood), "BS" (binary segmentation), "WBS" (wild binary segmentation) and "PELT" (pruned exact linear time) algorithms.
#' @param dist_min an integer indicating the minimum distance between two successive candidate change-points, with a default value \eqn{floor(log(n))}.
#' @param ncps_max an integer indicating the maximum number of change-points searched for, with a default value \eqn{ceiling(n^0.4)}.
#' @param pelt_pen_val a numeric vector specifying the collection of candidate values of the penalty if the "PELT" algorithm is used.
#' @param pelt_K a numeric value to adjust the pruning tactic, usually is taken to be 0 if negative log-likelihood is used as a cost; more details can be found in Killick et al. (2012).
#' @param wbs_nintervals an integer indicating the number of random intervals drawn in the "WBS" algorithm and a default value 500 is used.
#' @param criterion a character string indicating which model selection criterion, "cross- validation" ("CV") or "multiple-splitting" ("MS"), is used.
#' @param times an integer indicating how many times of sample-splitting should be performed; if "CV" criterion is used, it should be set as 2.
#' @param model a character string indicating the considered change model, and will be set as "custom" if not provided.
#' @param g_smry a customized R function of two arguments \code{dataset} and \code{param.opt}, which calculates the summary statistics that will be needed in evaluations of the cost. The returned object is a list for convenience.
#' @param easy_cost a customized R function of three arguments \code{data_smry}, \code{s} and \code{e}, that evaluates the cost for a date segment form observed time point $s$ to $e$. The argument \code{data_smry} inherits from the returned list of the function \code{g_smry}.
#' @return \code{cpss.custom} returns an object of an \proglang{S4} class, called "\code{cpss}", which collects data and information required for further change-point analyses and summaries.
#' \describe{
#'   \item{\code{dat}}{an \code{ANY} object inheriting form the type of user-input data}
#'   \item{\code{mdl}}{a character string describing considered change-point model}
#'   \item{\code{algo}}{a character string indicating user-specified change-point searching algorithm}
#'   \item{\code{algo_param_dim}}{an integer indicating user-specified maximum number of change-points searched for if the algorithm is chosen among "SN", "BS" and "WBS", or a numeric vector collecting user-specified values for the penalty if the algorithm is "PELT"}
#'   \item{\code{SC}}{a character string indicating model selection criterion}
#'   \item{\code{ncps}}{an integer giving estimated number of change-points based on the entire data}
#'   \item{\code{pelt_pen}}{a numeric value indicating selected penalty value if the "PELT" algorithm is performed based on the entire data}
#'   \item{\code{cps}}{a numeric vector of detected change-points based on the entire data}
#'   \item{\code{params}}{a list object, each of whose members is a list containing estimated parameters in the corresponding segment}
#'   \item{\code{S_vals}}{a numeric vector of candidate model dimensions in terms of a sequence of numbers of change-points or values of penalty}
#'   \item{\code{SC_vals}}{a numeric matrix, each column of which records the values of criterion based on the validation data under the corresponding model dimension (\code{S_vals}), and each row of which represents a splitting at each time}
#' }
#' @export
#'
#' @references
#' Killick, R., Fearnhead, P., and Eckley, I. A. (2012). Optimal Detection of Changepoints With a Linear Computational Cost. Journal of the American Statistical Association, 107(500):1590â€“1598.
#' @examples
#' library("cpss")
#' if (!requireNamespace("L1pack", quietly = TRUE)) {
#'   stop("Please install the package \"L1pack\".")
#' }
#' set.seed(666)
#' n <- 1000
#' tau <- c(250, 500, 750)
#' tau_ext <- c(0, tau, n)
#' be0 <- c(1, 1, 0, -1)
#' be <- c(1, -1, -1, 1)
#' seg_len <- diff(c(0, tau, n))
#' x <- rnorm(n)
#' eta <- unlist(lapply(seq(1, length(tau) + 1), function(k) {
#'   be0[k] + be[k] * x[(tau_ext[k] + 1):tau_ext[k + 1]]
#' }))
#' ep <- L1pack::rlaplace(n)
#' y <- eta + ep
#' g_subdat_l1 <- function(dat, indices) {
#'   matrix(dat[indices, ], sum(indices), ncol(dat))
#' }
#' g_param_l1 <- function(dat, param.opt = NULL) {
#'   y <- dat[, 1]
#'   x <- dat[, -1]
#'   return(L1pack::l1fit(x, y)$coefficients)
#' }
#' g_cost_l1 <- function(dat, param) {
#'   y <- dat[, 1]
#'   x <- dat[, -1]
#'   return(sum(abs(y - cbind(1, x) %*% as.matrix(param))))
#' }
#' res <- cpss.custom(
#'   dataset = cbind(y, x), n = n,
#'   g_subdat = g_subdat_l1, g_param = g_param_l1, g_cost = g_cost_l1,
#'   algorithm = "BS", dist_min = 10, ncps_max = 10,
#'   g_smry = NULL, easy_cost = NULL
#' )
#' summary(res)
#' # 250  500  744
#' do.call(rbind,res@params)
#' # Intercept          X
#' # [1,]  0.9327557  0.9558247
#' # [2,]  0.9868086 -1.0254999
#' # [3,] -0.0464067 -0.9076744
#' # [4,] -0.9746133  0.9671701
#' @importFrom methods new
cpss.custom <- function(dataset, n, g_subdat, g_param, g_cost, algorithm = "BS", dist_min = floor(log(n)), ncps_max = ceiling(n^0.4), pelt_pen_val = NULL, pelt_K = 0, wbs_nintervals = 500, criterion = "CV", times = 2, model = NULL, g_smry = NULL, easy_cost = NULL, param.opt = NULL) {

  out <- new("cpss")
  out@dat <- dataset
  out@mdl <- ifelse(is.null(model), "custom", model)
  out@algo <- algorithm
  if (out@algo %in% c("SN", "BS", "WBS")) {
    out@algo_param_dim <- ncps_max
  } else if (out@algo == "PELT") {
    out@algo_param_dim <- pelt_pen_val
  } else {
    stop("Not supported searching algorithm!")
  }
  out@SC <- criterion
  out@S_vals <- 1:ncps_max

  # OPS
  idx <- 1:n
  is_O <- idx %% 2 == 1
  n_O <- sum(is_O)
  if (out@SC == "CV" & times > 2) {
    stop("The argument \"times\" must be 2 if use \"CV\" criterion!")
  }
  idx_O <- vector("list", times)
  if (out@SC == "CV") {
    idx_O[[1]] <- is_O
    idx_O[[2]] <- !is_O
  } else if (out@SC == "MS") {
    for (i in 1:times) {
      is_O_sel <- sample(c(TRUE, FALSE), n_O, replace = TRUE)
      is_O_MS <- c(rbind(is_O_sel, (!is_O_sel)))[1:n]
      idx_O[[i]] <- is_O_MS
    }
  } else {
    stop("Not supported slection criterion!")
  }

  # searching and selection
  out@SC_vals <- matrix(NA, times, length(out@S_vals))
  for (i in 1:times) {
    res_i <- COPS(out@dat, n, idx_O[[i]], g_subdat, g_param, g_cost, out@algo, dist_min, ncps_max, pelt_pen_val, pelt_K, wbs_nintervals, out@mdl, g_smry, easy_cost, param.opt)
    out@SC_vals[i, ] <- res_i$cost_val
  }
  out@ncps <- which.min(apply(out@SC_vals, 2, sum))

  # refit
  res_refit <- EST(dataset, n, g_subdat, g_param, g_cost, out@algo, dist_min, out@ncps, pelt_pen_val, pelt_K, wbs_nintervals, model, g_smry, easy_cost, param.opt)
  if (out@algo %in% c("SN", "BS", "WBS")) {
    out@cps <- sort(res_refit[out@ncps, 1:out@ncps])
  } else if (out@algo == "PELT") {
    pelt_idx <- max(which(apply(res_refit > 0, 2, sum) >= out@ncps))
    out@pelt_pen <- pelt_pen_val[pelt_idx]
    out@cps <- sort(res_refit[res_refit[, pelt_idx] > 0, pelt_idx])
  } else {
    stop("Not supported searching algorithm!")
  }
  ID <- rep(1:(length(out@cps) + 1), c(out@cps, n) - c(0, out@cps))
  for (j in 1:(length(out@cps) + 1)) {
    subdat_j <- g_subdat(dataset, ID == j)
    out@params[[j]] <- g_param(subdat_j, param.opt)
  }

  update.inputs <- list()
  update.inputs$n <- n
  update.inputs$g_subdat <- g_subdat
  update.inputs$g_param <- g_param
  update.inputs$g_cost <- g_cost
  update.inputs$dist_min <- dist_min
  update.inputs$ncps_max <- ncps_max
  update.inputs$pelt_pen_val <- pelt_pen_val
  update.inputs$pelt_K <- pelt_K
  update.inputs$wbs_nintervals <- wbs_nintervals
  update.inputs$g_smry <- g_smry
  update.inputs$easy_cost <- easy_cost
  update.inputs$param.opt <- param.opt
  out@update.inputs <- update.inputs

  if (out@mdl == "custom") {
    out@call <- list(call = match.call())
  }

  return(out)
}
