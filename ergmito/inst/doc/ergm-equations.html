<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />

<meta name="author" content="George G Vega Yon" />

<meta name="date" content="2020-08-10" />

<title>ERGM equations</title>

<script>// Hide empty <a> tag within highlighted CodeBlock for screen reader accessibility (see https://github.com/jgm/pandoc/issues/6352#issuecomment-626106786) -->
// v0.0.1
// Written by JooYoung Seo (jooyoung@psu.edu) and Atsushi Yasumoto on June 1st, 2020.

document.addEventListener('DOMContentLoaded', function() {
  const codeList = document.getElementsByClassName("sourceCode");
  for (var i = 0; i < codeList.length; i++) {
    var linkList = codeList[i].getElementsByTagName('a');
    for (var j = 0; j < linkList.length; j++) {
      if (linkList[j].innerHTML === "") {
        linkList[j].setAttribute('aria-hidden', 'true');
      }
    }
  }
});
</script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    for (var j = 0; j < rules.length; j++) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") continue;
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') continue;
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>



<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">ERGM equations</h1>
<h4 class="author">George G Vega Yon</h4>
<h4 class="date">2020-08-10</h4>




<p>The likelihood of an Exponential Random Graph Model (ERGM) is defined as follows:</p>
<p><span class="math display">\[
\text{P}\left(\left.\mathbf{Y}= \mathbf{y}\vphantom{X = x}\right|\vphantom{\mathbf{Y}= \mathbf{y}}X = x\right) = \frac{%
  \text{exp}\left\{{\theta}^{\text{t}}g\left(\mathbf{y}, x\right)\right\} %
  }{%
  \sum_{\mathbf{y}&#39;\in\mathcal{Y}} \text{exp}\left\{{\theta}^{\text{t}}g\left(\mathbf{y}&#39;, x\right)\right\} %
  },\quad \forall \mathbf{y}\in\mathcal{Y}
\]</span></p>
<p>Where <span class="math inline">\(\mathbf{y}\in\mathcal{Y}\)</span> is a random graph, <span class="math inline">\(X\)</span> is a vector of attributes, <span class="math inline">\(\theta\)</span> is a column-vector of length <span class="math inline">\(k\)</span> (model parameters), and <span class="math inline">\(g\left(\cdot\right)\)</span> is a function that returns a column-vector of sufficient statistics, also of length <span class="math inline">\(k\)</span>. In general, from the computational point of view, it is easier to manipulate the likelihood function centered at the observed sufficient statistics, this is:</p>
<p><span class="math display">\[
\text{P}\left(\left.\mathbf{Y}= \mathbf{y}\vphantom{X = x}\right|\vphantom{\mathbf{Y}= \mathbf{y}}X = x\right) = \frac{1}{%
  \sum_{\mathbf{y}&#39;\in\mathcal{Y}} \text{exp}\left\{{\theta}^{\text{t}}\Delta{}g\left(\mathbf{y}&#39;,x\right)\right\} %
  },\quad \forall \mathbf{y}\in\mathcal{Y}
\]</span></p>
<p>Where <span class="math inline">\(\Delta{}g\left(\mathbf{y}&#39;\right) = g\left(\mathbf{y}&#39;,x\right) - g\left(\mathbf{y}, x\right)\)</span>. In the case of <code>ergmito</code>, we usually look at a pooled model with <span class="math inline">\(n\)</span> networks, i.e.</p>
<p><span class="math display">\[
\prod_{i \in N}\text{P}\left(\left.\mathbf{Y}= \mathbf{y}_i\vphantom{X = x_i}\right|\vphantom{\mathbf{Y}= \mathbf{y}_i}X = x_i\right) = \prod_{i \in N}\frac{1}{%
  \sum_{\mathbf{y}_i&#39;\in\mathcal{Y}} \text{exp}\left\{{\theta}^{\text{t}}\Delta g\left(\mathbf{y}_i&#39;\right)\right\} %
  },\quad \forall \mathbf{y}_i\in\mathcal{Y}
\]</span></p>
<p>Where <span class="math inline">\(N\equiv\{1,\dots, n\}\)</span> is a vector of indices.</p>
<div id="log-likelihood" class="section level2">
<h2>log-likelihood</h2>
<p>In the case of a single network, the model’s log-likelihood is given by</p>
<p><span class="math display">\[
\text{log}\left(\text{P}\left(\cdot\right)\right) = - 
  \text{log}\left( % 
    \sum_{\mathbf{y}&#39;\in\mathbf{Y}}\text{exp}\left\{{\theta}^{\text{t}}\Delta g\left(\mathbf{y}&#39;\right)\right\} %
    \right)
\]</span> In general, we can reduce the computational complexity of this calculations by looking at the isomorphic sufficient statistics, this is, group up elements based on the set of unique vectors of sufficient statistics:</p>
<p><span class="math display">\[
- \text{log}\left( % 
    \sum_{\mathbf{s}\in\mathcal{S}}\mathbf{w}_\mathbf{s}\text{exp}\left\{{\theta}^{\text{t}}\mathbf{s}\right\} %
    \right)
\]</span></p>
<p>Where <span class="math inline">\(\mathcal{S}\)</span> is the support of the sufficient statistics under <span class="math inline">\(\mathcal{Y}\)</span>, <span class="math inline">\(\mathbf{s}\in\mathcal{S}\)</span> is one of its realizations, and <span class="math inline">\(\mathbf{w}_\mathbf{s}\equiv|\left\{\mathbf{y}\in\mathcal{Y}: \Delta{}g\left(\mathbf{y}\right) = \mathbf{s}\right\}|\)</span> is the number of networks in <span class="math inline">\(\mathcal{Y}\)</span> which centered sufficient statistics equal <span class="math inline">\(\mathbf{s}\)</span>. Furthermore, we can write this in matrix form:</p>
<p><span class="math display">\[
- %
  \text{log}\left( % 
    \mathbf{W}\times \text{exp}\left\{\mathbf{S}\times \theta\right\}  %
    \right)
\]</span></p>
<p>Where <span class="math inline">\(\mathbf{W}\equiv\{\mathbf{w}_\mathbf{s}\}_{\mathbf{s}\in\mathbf{S}}\)</span> is a row vector of, length <span class="math inline">\(w\)</span> and <span class="math inline">\(\mathbf{S}\)</span> is a matrix of size <span class="math inline">\(w\times k\)</span>. The log-likelihood of a pooled model is simply the sum of the individual ones.</p>
</div>
<div id="gradient" class="section level2">
<h2>Gradient</h2>
<p>The partial derivative of the log-likelihood with respect to <span class="math inline">\(j\)</span>-th parameter equals:</p>
<p><span class="math display">\[
\frac{\delta}{\delta\theta_j}\text{log}\left(\text{P}\left(\cdot\right)\right) = % 
  - \frac{ %
    \sum_{\mathbf{s}\in\mathcal{S}}\mathbf{w}_\mathbf{s}\mathbf{s}_j\text{exp}\left\{{\theta}^{\text{t}}\mathbf{s}\right\} %
    }{ %
    \sum_{\mathbf{s}\in\mathcal{S}}\mathbf{w}_\mathbf{s}\text{exp}\left\{{\theta}^{\text{t}}\mathbf{s}\right\} %
    }, \quad\forall j
\]</span></p>
<p>We can also write this using matrix notation as follows:</p>
<p><span class="math display">\[
\nabla\text{log}\left(\text{P}\left(\cdot\right)\right) = %
  - %
  {\mathbf{S}}^{\text{t}}\times \left[ \mathbf{W}\circ \text{exp}\left\{\mathbf{S}\times \theta\right\} \right]/ %
  \lambda({\theta})
\]</span></p>
<p>Where <span class="math inline">\(\circ\)</span> is the element-wise product and <span class="math inline">\(\lambda({\theta}) = \mathbf{W}\times \text{exp}\left\{\mathbf{S}\times \theta\right\}\)</span>.</p>
</div>
<div id="hessian" class="section level2">
<h2>Hessian</h2>
<p>In the case of the hessian, each <span class="math inline">\((j, l)\)</span> element of, <span class="math inline">\(\frac{\delta^2}{\delta\theta_k\delta\theta_u}\text{log}\left(\text{P}\left(\cdot\right)\right)\)</span>, can be computed as:</p>
<p><span class="math display">\[
\frac{%
  -\left(\sum_{\mathbf{s}&#39;\in\mathcal{S}}\mathbf{s}_j&#39;\mathbf{s}_l&#39;\mathbf{w}_\mathbf{s}\text{exp}\left\{{\theta}^{\text{t}} \mathbf{s}\right\}\right)
}{%
  \lambda(\theta)%
} + \frac{%
  \left(\sum_{\mathbf{s}&#39;\in\mathcal{S}}\mathbf{s}_j&#39;\mathbf{w}_\mathbf{s}\text{exp}\left\{{\theta}^{\text{t}} \mathbf{s}\right\}\right)
    \left(\sum_{\mathbf{s}&#39;\in\mathcal{S}}\mathbf{s}_l&#39;\mathbf{w}_\mathbf{s}\text{exp}\left\{{\theta}^{\text{t}} \mathbf{s}\right\}\right)
}{%
  \lambda(\theta)^2%
}
\]</span> Where <span class="math inline">\(\mathbf{s}_j\)</span> as the <span class="math inline">\(j\)</span>-th element of the vector <span class="math inline">\(\mathbf{s}\)</span>. Once again, we can simplify this using matrix notation:</p>
<p><span class="math display">\[
\frac{%
  -\mathbf{W}\times\left[\mathbf{S}_j\circ\mathbf{S}_l \circ \text{exp}\left\{\mathbf{S}\times\theta\right\}\right]%
}{%
  \lambda(\theta)%
} + \frac{%
\left(\mathbf{W}\times\left[\mathbf{S}_j \circ \text{exp}\left\{\mathbf{S}\times\theta\right\}\right]\right)
  \left(\mathbf{W}\times\left[\mathbf{S}_l \circ \text{exp}\left\{\mathbf{S}\times\theta\right\}\right]\right)
}{%
  \lambda(\theta)^2%
}
\]</span></p>
<p>Where <span class="math inline">\(\mathbf{S}_j\)</span> is the <span class="math inline">\(j\)</span>-th column of the matrix <span class="math inline">\(\mathbf{S}\)</span>.</p>
</div>
<div id="limiting-values" class="section level1">
<h1>Limiting values</h1>
<p>In the case that the MLE does not exists, i.e. <span class="math inline">\(\theta_k\to\pm\infty\)</span>, which occurs when the observed sufficient statistics are not in the interior of the space, for example, a fully connected network, the limit of the log-likelihood, the gradient, and hessian are finite. This is relevant as some special care needs to be taken when dealing with these cases.</p>
<p>While in general models in which the MLEs diverge may seem uninteresting, the fact that ERGMs describe a discrete and not continuous random variable makes this type of event easier to observed when compared to other families of distributions. Furthermore, in the case of methods such as bootstrapping, forward/backward selection, or other classes of algorithms that involve some level of automatization during the model fitting process, it is important to know how to correctly deal with the non-existence of MLEs. Fortunately, as we will show, the log-likelihood and its derivatives are well defined in such cases.</p>
<p>The main principle here is what happens in the argument of the exponential function that populates these functions. Depending on what is <span class="math inline">\(\mathbf{s}_k\)</span>, two cases follow:</p>
<ol style="list-style-type: decimal">
<li><p><strong>The observe value of the <span class="math inline">\(k\)</span>-th sufficient statistic is in the <em>lower</em> bound</strong> <span class="math inline">\(\mathbf{s}_k = \min_{\mathbf{s}&#39;\in\mathcal{S}}\mathbf{s}_{k}&#39;\)</span> This happens, for example, when trying to fit a model with triangles where there are no observed triangles. In this case, with <span class="math inline">\(\mathbf{s}_k&#39; \geq 0\)</span> for all cases, the theoretical MLE for <span class="math inline">\(\theta_k\)</span> goes to <span class="math inline">\(-\infty\)</span>, thus, in the limit, the expression <span class="math display">\[
  \lim_{\theta_k\to-\infty}\text{exp}\left\{{\theta}^{\text{t}}\mathbf{s}&#39;\right\} = \left\{\begin{array}{ll} %
  \text{exp}\left\{\sum_{j\neq k}\mathbf{s}_j&#39;\theta_j\right\} &amp;\quad\text{if }\mathbf{s}_k&#39; = 0 \\
  0 &amp; \quad\text{if }\mathbf{s}_k&#39; &gt; 0
  \end{array}\right.
  \]</span></p></li>
<li><p><strong>The observe value of the <span class="math inline">\(k\)</span>-th sufficient statistic is in the <em>upper</em> bound</strong> <span class="math inline">\(\mathbf{s}_k = \min_{\mathbf{s}&#39;\in\mathcal{S}}\mathbf{s}_k&#39;\)</span> The most common case is when the sufficient statistic is satturated, for example, in a fully connected graph, where the MLE goes to infinity, <span class="math inline">\(\theta_k\to+\infty\)</span>. Similar to before, since <span class="math inline">\(\mathbf{s}_k&#39; \leq 0\)</span> for all cases, in the limit the previous expression is well defined: <span class="math display">\[
  \lim_{\theta_k\to+\infty}\text{exp}\left\{{\theta}^{\text{t}}\mathbf{s}&#39;\right\} = \left\{\begin{array}{ll} %
  \text{exp}\left\{\sum_{j\neq k}\mathbf{s}_j&#39;\theta_j\right\} &amp;\quad\text{if }\mathbf{s}_k&#39; = 0 \\
  0 &amp; \quad\text{if }\mathbf{s}_k&#39; &lt; 0
  \end{array}\right.
  \]</span></p></li>
</ol>
<p>The two previous points can be interpreted as only graphs whose <span class="math inline">\(k\)</span>-th sufficient statistic matches that of the observed data influence the model. Therefore, a key to compute the limiting values of the log-likelihood, gradient, and hessian will be on partitioning the summations over <span class="math inline">\(\mathbf{s}&#39;\in\mathcal{S}\)</span> into two different sets as follows:</p>
<p><span class="math display">\[\begin{align}
\mathcal{S}_0 &amp; \equiv \{\mathbf{s}\in\mathcal{S}: \mathbf{s}_u = 0, \forall u\in U\} \\
\mathcal{S}_1 &amp; \equiv \mathcal{S}\setminus\mathcal{S}_0
\end{align}\]</span></p>
<p>Where <span class="math inline">\(U\)</span> is the set of observed sufficient statistics that are on the boundary and thus have an MLE that diverges to <span class="math inline">\(\pm\infty\)</span>. In this partition <span class="math inline">\(\mathcal{S}_0\)</span> contains all the realizations of sufficient statistics for which the statistics in <span class="math inline">\(U\)</span> are equal to the observed ones. With this definition in hand, we will now show what is the asymptotic behavior of the log-likelihood, gradient, and hessian when one or more observed sufficient statistics are on not in the interior of the support.</p>
<div id="log-likelihood-1" class="section level2">
<h2>Log-likelihood</h2>
<p>Using the partition of <span class="math inline">\(\mathcal{S}\)</span>, the log-likelihood can be written as follows</p>
<p><span class="math display">\[
-\text{log}\left( % 
    \sum_{\mathbf{s}&#39;\in\mathcal{S}_0}\mathbf{w}_{\mathbf{s}&#39;}\text{exp}\left\{\sum_{j\not\in U}\mathbf{s}_j&#39;\theta_j\right\} + %
    \sum_{\mathbf{s}&#39;\in\mathcal{S}_1}\mathbf{w}_{\mathbf{s}&#39;}\text{exp}\left\{{\theta}^{\text{t}}\Delta g\left(\mathbf{y}&#39;\right)\right\} 
    \right)
\]</span></p>
<p>Then, WLOG as <span class="math inline">\(\theta_u\to-\infty\)</span>, positive if <span class="math inline">\(\mathbf{s}_u\)</span> is in the upper bound, we have:</p>
<p><span class="math display">\[
\begin{align}
&amp; \lim_{\theta_u\to-\infty} -\text{log}\left( % 
    \sum_{\mathbf{s}&#39;\in\mathcal{S}_0}\mathbf{w}_{\mathbf{s}&#39;}\text{exp}\left\{\sum_{j\not\in U}\mathbf{s}_j&#39;\theta_j\right\} + %
    \sum_{\mathbf{s}&#39;\in\mathcal{S}_1}\mathbf{w}_{\mathbf{s}&#39;}\text{exp}\left\{{\theta}^{\text{t}}\Delta g\left(\mathbf{y}&#39;\right)\right\} 
    \right) \\
&amp; = -\text{log}\left( \lim_{\theta_u\to-\infty} % 
    \sum_{\mathbf{s}&#39;\in\mathcal{S}_0}\mathbf{w}_{\mathbf{s}&#39;}\text{exp}\left\{\sum_{j\not\in U}\mathbf{s}_j&#39;\theta_j\right\} + %
    \sum_{\mathbf{s}&#39;\in\mathcal{S}_1}\mathbf{w}_{\mathbf{s}&#39;}\text{exp}\left\{{\theta}^{\text{t}}\Delta g\left(\mathbf{y}&#39;\right)\right\} 
    \right) \\
&amp; = -\text{log}\left( % 
    \sum_{\mathbf{s}&#39;\in\mathcal{S}_0}\mathbf{w}_{\mathbf{s}&#39;}\text{exp}\left\{\sum_{j\not\in U}\mathbf{s}_j&#39;\theta_j\right\} 
    \right) 
\end{align}
\]</span></p>
<p>Where the second equality follows from the fact that the logarithm function is continuous in <span class="math inline">\((0,1)\)</span>. We can see this in the following example:</p>
<p>Suppose that we have five networks of size 4 as the one included in the ergmito package, <code>fivenets</code>, and we wanted to fit the following model <code>fivenets ~ edges + triadcensus(15)</code>, with <code>triadcensus(15)</code> equal to a fully connected triad, also known as triad class 300 using Davis and Leinhardt triadic classification system. Since the <code>fivenets</code> dataset has no fully connected triad, the MLE of that term diverges:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1"></a><span class="kw">library</span>(ergmito)</span>
<span id="cb1-2"><a href="#cb1-2"></a><span class="kw">data</span>(fivenets)</span>
<span id="cb1-3"><a href="#cb1-3"></a>(ans &lt;-<span class="st"> </span><span class="kw">ergmito</span>(fivenets <span class="op">~</span><span class="st"> </span>edges <span class="op">+</span><span class="st"> </span><span class="kw">triadcensus</span>(<span class="dv">15</span>)))</span></code></pre></div>
<pre><code>## Warning: The observed statistics (target.statistics) are near or at the boundary
## of its support, i.e. the Maximum Likelihood Estimates maynot exist or be hard to
## be estimated. In particular, the statistic(s) &quot;edges&quot;, &quot;triadcensus.300&quot;.</code></pre>
<pre><code>## 
## ERGMito estimates
## note: A subset of the parameters estimates was replaced with +/-Inf,  and the Hessian matrix is not p.s.d.
## 
##  Coefficients:
##           edges  triadcensus.300  
##         -0.6851             -Inf</code></pre>
<p>The log-likelihood of this model can be computed directly with ergmito using a large negative instead of <code>-Inf</code>, or by using the equation that shows the limiting value of the log-likelihood:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1"></a><span class="co"># Approach using the limiting value</span></span>
<span id="cb4-2"><a href="#cb4-2"></a>l &lt;-<span class="st"> </span><span class="kw">with</span>(ans<span class="op">$</span>formulae, {</span>
<span id="cb4-3"><a href="#cb4-3"></a>  <span class="kw">sapply</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">nnets</span>(ans), <span class="cf">function</span>(i) {</span>
<span id="cb4-4"><a href="#cb4-4"></a>    <span class="co"># Preparing suff stats</span></span>
<span id="cb4-5"><a href="#cb4-5"></a>    S &lt;-<span class="st"> </span><span class="kw">t</span>(<span class="kw">t</span>(stats_statmat[[i]]) <span class="op">-</span><span class="st"> </span>target_stats[i, ])</span>
<span id="cb4-6"><a href="#cb4-6"></a>    W &lt;-<span class="st"> </span>stats_weights[[i]]</span>
<span id="cb4-7"><a href="#cb4-7"></a>    theta &lt;-<span class="st"> </span><span class="kw">coef</span>(ans)[<span class="st">&quot;edges&quot;</span>]</span>
<span id="cb4-8"><a href="#cb4-8"></a>    </span>
<span id="cb4-9"><a href="#cb4-9"></a>    <span class="co"># Index of members of S0</span></span>
<span id="cb4-10"><a href="#cb4-10"></a>    s0idx &lt;-<span class="st"> </span><span class="kw">which</span>(S[,<span class="dv">2</span>] <span class="op">==</span><span class="st"> </span><span class="dv">0</span>)</span>
<span id="cb4-11"><a href="#cb4-11"></a>    </span>
<span id="cb4-12"><a href="#cb4-12"></a>    <span class="op">-</span><span class="st"> </span><span class="kw">log</span>(<span class="kw">sum</span>(W[s0idx] <span class="op">*</span><span class="st"> </span><span class="kw">exp</span>(S[s0idx,<span class="dv">1</span>] <span class="op">*</span><span class="st"> </span>theta)))</span>
<span id="cb4-13"><a href="#cb4-13"></a>  })</span>
<span id="cb4-14"><a href="#cb4-14"></a>})</span>
<span id="cb4-15"><a href="#cb4-15"></a><span class="kw">sum</span>(l)</span></code></pre></div>
<pre><code>## [1] -38.16338</code></pre>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1"></a><span class="co"># Which should be equivalent to the approach with large negative number</span></span>
<span id="cb6-2"><a href="#cb6-2"></a>ans<span class="op">$</span>formulae<span class="op">$</span><span class="kw">loglik</span>(<span class="kw">c</span>(<span class="kw">coef</span>(ans)[<span class="st">&quot;edges&quot;</span>], <span class="fl">-1e100</span>))</span></code></pre></div>
<pre><code>## [1] -38.16338</code></pre>
</div>
<div id="gradient-1" class="section level2">
<h2>Gradient</h2>
<p>The gradient for <span class="math inline">\(\theta_j\)</span> equals</p>
<p><span class="math display">\[
- \frac{ %
    \sum_{\mathbf{s}\in\mathcal{S}}\mathbf{w}_\mathbf{s}\mathbf{s}_j\text{exp}\left\{{\theta}^{\text{t}}\mathbf{s}\right\} %
    }{ %
    \sum_{\mathbf{s}\in\mathcal{S}}\mathbf{w}_\mathbf{s}\text{exp}\left\{{\theta}^{\text{t}}\mathbf{s}\right\} %
    } = %
- \frac{ %
    \sum_{\mathbf{s}\in\mathcal{S}_0}\mathbf{w}_\mathbf{s}\mathbf{s}_j\text{exp}\left\{\sum_{j\not\in U}\theta_j\mathbf{s}_j\right\} +
    \sum_{\mathbf{s}\in\mathcal{S}_1}\mathbf{w}_\mathbf{s}\mathbf{s}_j\text{exp}\left\{{\theta}^{\text{t}}\mathbf{s}\right\} %
    }{ %
    \sum_{\mathbf{s}\in\mathcal{S}_0}\mathbf{w}_\mathbf{s}\text{exp}\left\{\sum_{j\not\in U}\theta_j\mathbf{s}_j\right\} + %
    \sum_{\mathbf{s}\in\mathcal{S}_1}\mathbf{w}_\mathbf{s}\text{exp}\left\{{\theta}^{\text{t}}\mathbf{s}\right\} %
    }
\]</span></p>
<p>WLOG if <span class="math inline">\(\mathbf{s}_u = \min_{\mathbf{s}&#39;\in\mathcal{S}}\mathbf{s}_u&#39;\)</span> the limit of the above expression as <span class="math inline">\(\theta_u\to-\infty\)</span> is evaluated as follows:</p>
<p><span class="math display">\[
\begin{align}
\lim_{\theta_u\to-\infty} &amp; - \frac{ %
    \sum_{\mathbf{s}\in\mathcal{S}_0}\mathbf{w}_\mathbf{s}\mathbf{s}_j\text{exp}\left\{\sum_{j\not\in U}\theta_j\mathbf{s}_j\right\} +
    \sum_{\mathbf{s}\in\mathcal{S}_1}\mathbf{w}_\mathbf{s}\mathbf{s}_j\text{exp}\left\{{\theta}^{\text{t}}\mathbf{s}\right\} %
    }{ %
    \sum_{\mathbf{s}\in\mathcal{S}_0}\mathbf{w}_\mathbf{s}\text{exp}\left\{\sum_{j\not\in U}\theta_j\mathbf{s}_j\right\} + %
    \sum_{\mathbf{s}\in\mathcal{S}_1}\mathbf{w}_\mathbf{s}\text{exp}\left\{{\theta}^{\text{t}}\mathbf{s}\right\} %
    }  \\ &amp; = %
- \frac{ %
    \sum_{\mathbf{s}\in\mathcal{S}_0}\mathbf{w}_\mathbf{s}\mathbf{s}_j\text{exp}\left\{\sum_{j\not\in U}\theta_j\mathbf{s}_j\right\}
    }{ %
    \sum_{\mathbf{s}\in\mathcal{S}_0}\mathbf{w}_\mathbf{s}\text{exp}\left\{\sum_{j\not\in U}\theta_j\mathbf{s}_j\right\}
    }
\end{align}
\]</span></p>
<p>If <span class="math inline">\(j = u\)</span>, the above expression reduces to 0 as <span class="math inline">\(\mathbf{s}&#39;_u = 0\forall \mathbf{s}&#39;\in \mathcal{S}_0\)</span>, otherwise the number is well defined. We can calculate the gradient of the triad 300 model alternatively using the above expression:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1"></a>g &lt;-<span class="st"> </span><span class="kw">with</span>(ans<span class="op">$</span>formulae, {</span>
<span id="cb8-2"><a href="#cb8-2"></a>  <span class="kw">sapply</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">nnets</span>(ans), <span class="cf">function</span>(i) {</span>
<span id="cb8-3"><a href="#cb8-3"></a>    <span class="co"># Preparing suff stats</span></span>
<span id="cb8-4"><a href="#cb8-4"></a>    S &lt;-<span class="st"> </span><span class="kw">t</span>(<span class="kw">t</span>(stats_statmat[[i]]) <span class="op">-</span><span class="st"> </span>target_stats[i, ])</span>
<span id="cb8-5"><a href="#cb8-5"></a>    W &lt;-<span class="st"> </span>stats_weights[[i]]</span>
<span id="cb8-6"><a href="#cb8-6"></a>    theta &lt;-<span class="st"> </span><span class="kw">coef</span>(ans)[<span class="st">&quot;edges&quot;</span>]</span>
<span id="cb8-7"><a href="#cb8-7"></a>    </span>
<span id="cb8-8"><a href="#cb8-8"></a>    <span class="co"># Index of members of S0</span></span>
<span id="cb8-9"><a href="#cb8-9"></a>    s0idx &lt;-<span class="st"> </span><span class="kw">which</span>(S[,<span class="dv">2</span>] <span class="op">==</span><span class="st"> </span><span class="dv">0</span>)</span>
<span id="cb8-10"><a href="#cb8-10"></a>    </span>
<span id="cb8-11"><a href="#cb8-11"></a>    <span class="op">-</span><span class="st"> </span><span class="kw">sum</span>(W[s0idx] <span class="op">*</span><span class="st"> </span>S[s0idx,<span class="dv">1</span>] <span class="op">*</span><span class="st"> </span><span class="kw">exp</span>(S[s0idx,<span class="dv">1</span>] <span class="op">*</span><span class="st"> </span>theta))<span class="op">/</span></span>
<span id="cb8-12"><a href="#cb8-12"></a><span class="st">      </span><span class="kw">sum</span>(W[s0idx] <span class="op">*</span><span class="st"> </span><span class="kw">exp</span>(S[s0idx,<span class="dv">1</span>] <span class="op">*</span><span class="st"> </span>theta))</span>
<span id="cb8-13"><a href="#cb8-13"></a>  })</span>
<span id="cb8-14"><a href="#cb8-14"></a>})</span>
<span id="cb8-15"><a href="#cb8-15"></a><span class="kw">sum</span>(g)</span></code></pre></div>
<pre><code>## [1] 0.002926372</code></pre>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1"></a><span class="co"># Which is equivalent to</span></span>
<span id="cb10-2"><a href="#cb10-2"></a>ans<span class="op">$</span>formulae<span class="op">$</span><span class="kw">grad</span>(<span class="kw">c</span>(<span class="kw">coef</span>(ans)[<span class="st">&quot;edges&quot;</span>], <span class="fl">-1e100</span>))</span></code></pre></div>
<pre><code>##             [,1]
## [1,] 0.002926372
## [2,] 0.000000000</code></pre>
</div>
<div id="hessian-1" class="section level2">
<h2>Hessian</h2>
<p>Just like the other cases, we can rewrite the hessian distingushing between <span class="math inline">\(\mathcal{S}_0\)</span> and <span class="math inline">\(\mathcal{S}_1\)</span>. Without rewriting the whole expression (which would be simply taking too much space), and WLOG, the limiting Hessian, and in particular, its <span class="math inline">\((j,l)\)</span>-th component, as <span class="math inline">\(\theta_u\to-\infty\)</span> equals:</p>
<p><span class="math display">\[
\begin{align}
&amp; \frac{%
  -\left(\sum_{\mathbf{s}&#39;\in\mathcal{S}_0}\mathbf{s}_j&#39;\mathbf{s}_l&#39;\mathbf{w}_\mathbf{s}\text{exp}\left\{\sum_{j\not\in U}\theta_j\mathbf{s}_j\right\}\right)
  }{%
  \sum_{\mathbf{s}\in\mathcal{S}_0}\mathbf{w}_\mathbf{s}\text{exp}\left\{\sum_{j\not\in U}\theta_j\mathbf{s}_j\right\}%
} + \\
&amp; \quad \frac{%
  \left(\sum_{\mathbf{s}&#39;\in\mathcal{S}_0}\mathbf{s}_j&#39;\mathbf{w}_\mathbf{s}\text{exp}\left\{\sum_{j\not\in U}\theta_j\mathbf{s}_j\right\}\right)
    \left(\sum_{\mathbf{s}&#39;\in\mathcal{S}_0}\mathbf{s}_l&#39;\mathbf{w}_\mathbf{s}\text{exp}\left\{\sum_{j\not\in U}\theta_j\mathbf{s}_j\right\}\right)
}{%
  \left(\sum_{\mathbf{s}\in\mathcal{S}_0}\mathbf{w}_\mathbf{s}\text{exp}\left\{\sum_{j\not\in U}\theta_j\mathbf{s}_j\right\}\right)^2%
}
\end{align}
\]</span></p>
<p>In the case of either <span class="math inline">\(j\)</span> or <span class="math inline">\(l\)</span> equal to <span class="math inline">\(u\)</span>, the hessian equals 0. For values other than <span class="math inline">\(u\)</span>, the hessian is non-zero, again, using the example with the triad 300 term we can compute the hessian as follows:</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1"></a>h &lt;-<span class="st"> </span><span class="kw">with</span>(ans<span class="op">$</span>formulae, {</span>
<span id="cb12-2"><a href="#cb12-2"></a>  <span class="kw">sapply</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">nnets</span>(ans), <span class="cf">function</span>(i) {</span>
<span id="cb12-3"><a href="#cb12-3"></a>    <span class="co"># Preparing suff stats</span></span>
<span id="cb12-4"><a href="#cb12-4"></a>    S &lt;-<span class="st"> </span><span class="kw">t</span>(<span class="kw">t</span>(stats_statmat[[i]]) <span class="op">-</span><span class="st"> </span>target_stats[i, ])</span>
<span id="cb12-5"><a href="#cb12-5"></a>    W &lt;-<span class="st"> </span>stats_weights[[i]]</span>
<span id="cb12-6"><a href="#cb12-6"></a>    theta &lt;-<span class="st"> </span><span class="kw">coef</span>(ans)[<span class="st">&quot;edges&quot;</span>]</span>
<span id="cb12-7"><a href="#cb12-7"></a>    </span>
<span id="cb12-8"><a href="#cb12-8"></a>    <span class="co"># Index of members of S0</span></span>
<span id="cb12-9"><a href="#cb12-9"></a>    s0idx &lt;-<span class="st"> </span><span class="kw">which</span>(S[,<span class="dv">2</span>] <span class="op">==</span><span class="st"> </span><span class="dv">0</span>)</span>
<span id="cb12-10"><a href="#cb12-10"></a>    </span>
<span id="cb12-11"><a href="#cb12-11"></a>    <span class="co"># First part</span></span>
<span id="cb12-12"><a href="#cb12-12"></a>    <span class="op">-</span><span class="st"> </span><span class="kw">sum</span>(W[s0idx] <span class="op">*</span><span class="st"> </span>S[s0idx,<span class="dv">1</span>]<span class="op">^</span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="kw">exp</span>(S[s0idx,<span class="dv">1</span>] <span class="op">*</span><span class="st"> </span>theta))<span class="op">/</span></span>
<span id="cb12-13"><a href="#cb12-13"></a><span class="st">      </span><span class="kw">sum</span>(W[s0idx] <span class="op">*</span><span class="st"> </span><span class="kw">exp</span>(S[s0idx,<span class="dv">1</span>] <span class="op">*</span><span class="st"> </span>theta)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb12-14"><a href="#cb12-14"></a><span class="st">      </span><span class="co"># Second bit</span></span>
<span id="cb12-15"><a href="#cb12-15"></a><span class="st">      </span><span class="kw">sum</span>(W[s0idx] <span class="op">*</span><span class="st"> </span>S[s0idx,<span class="dv">1</span>] <span class="op">*</span><span class="st"> </span><span class="kw">exp</span>(S[s0idx,<span class="dv">1</span>] <span class="op">*</span><span class="st"> </span>theta)) <span class="op">^</span><span class="st"> </span><span class="dv">2</span><span class="op">/</span></span>
<span id="cb12-16"><a href="#cb12-16"></a><span class="st">      </span><span class="kw">sum</span>(W[s0idx] <span class="op">*</span><span class="st"> </span><span class="kw">exp</span>(S[s0idx,<span class="dv">1</span>] <span class="op">*</span><span class="st"> </span>theta))<span class="op">^</span><span class="dv">2</span></span>
<span id="cb12-17"><a href="#cb12-17"></a>  })</span>
<span id="cb12-18"><a href="#cb12-18"></a>})</span>
<span id="cb12-19"><a href="#cb12-19"></a><span class="kw">sum</span>(h)</span></code></pre></div>
<pre><code>## [1] -12.97199</code></pre>
<p>Which should be equal to using the full hessian function but with a very large negative velue for the parameter associated with the statistic triad 300:</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1"></a>ans<span class="op">$</span>formulae<span class="op">$</span><span class="kw">hess</span>(<span class="kw">c</span>(<span class="kw">coef</span>(ans)[<span class="st">&quot;edges&quot;</span>], <span class="fl">-1e100</span>))</span></code></pre></div>
<pre><code>##           [,1] [,2]
## [1,] -12.97199    0
## [2,]   0.00000    0</code></pre>
<p>This last result is useful to then apply the Moore-Penrose generalized inverse and thus a pseudo-covariance matrix, which in some cases can be better than nothing. Furthermore, the limiting expressions of the log-likelihood, gradient, and hessian have less terms to be consider, which in principle results in faster calculations.</p>
</div>
</div>
<div id="references" class="section level1 unnumbered">
<h1>References</h1>
<div id="refs" class="references">
<div id="ref-ergmitoarxiv">
<p>Vega Yon, George, Andrew Slaughter, and Kayla de la Haye. 2019. “Exponential Random Graph Models for Little Networks.” arXiv preprint arXiv:1904.10406. <a href="https://arxiv.org/pdf/1904.10406.pdf">https://arxiv.org/pdf/1904.10406.pdf</a>.</p>
</div>
</div>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
