<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1">

<meta name="author" content="Geoffrey Thompson" />

<meta name="date" content="2019-11-14" />

<title>Discriminant Analysis for Matrix Variate Distributions</title>



<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    for (var j = 0; j < rules.length; j++) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") continue;
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') continue;
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>



<link href="data:text/css;charset=utf-8,body%20%7B%0Abackground%2Dcolor%3A%20%23fff%3B%0Amargin%3A%201em%20auto%3B%0Amax%2Dwidth%3A%20700px%3B%0Aoverflow%3A%20visible%3B%0Apadding%2Dleft%3A%202em%3B%0Apadding%2Dright%3A%202em%3B%0Afont%2Dfamily%3A%20%22Open%20Sans%22%2C%20%22Helvetica%20Neue%22%2C%20Helvetica%2C%20Arial%2C%20sans%2Dserif%3B%0Afont%2Dsize%3A%2014px%3B%0Aline%2Dheight%3A%201%2E35%3B%0A%7D%0A%23header%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0A%23TOC%20%7B%0Aclear%3A%20both%3B%0Amargin%3A%200%200%2010px%2010px%3B%0Apadding%3A%204px%3B%0Awidth%3A%20400px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Aborder%2Dradius%3A%205px%3B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Afont%2Dsize%3A%2013px%3B%0Aline%2Dheight%3A%201%2E3%3B%0A%7D%0A%23TOC%20%2Etoctitle%20%7B%0Afont%2Dweight%3A%20bold%3B%0Afont%2Dsize%3A%2015px%3B%0Amargin%2Dleft%3A%205px%3B%0A%7D%0A%23TOC%20ul%20%7B%0Apadding%2Dleft%3A%2040px%3B%0Amargin%2Dleft%3A%20%2D1%2E5em%3B%0Amargin%2Dtop%3A%205px%3B%0Amargin%2Dbottom%3A%205px%3B%0A%7D%0A%23TOC%20ul%20ul%20%7B%0Amargin%2Dleft%3A%20%2D2em%3B%0A%7D%0A%23TOC%20li%20%7B%0Aline%2Dheight%3A%2016px%3B%0A%7D%0Atable%20%7B%0Amargin%3A%201em%20auto%3B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dcolor%3A%20%23DDDDDD%3B%0Aborder%2Dstyle%3A%20outset%3B%0Aborder%2Dcollapse%3A%20collapse%3B%0A%7D%0Atable%20th%20%7B%0Aborder%2Dwidth%3A%202px%3B%0Apadding%3A%205px%3B%0Aborder%2Dstyle%3A%20inset%3B%0A%7D%0Atable%20td%20%7B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dstyle%3A%20inset%3B%0Aline%2Dheight%3A%2018px%3B%0Apadding%3A%205px%205px%3B%0A%7D%0Atable%2C%20table%20th%2C%20table%20td%20%7B%0Aborder%2Dleft%2Dstyle%3A%20none%3B%0Aborder%2Dright%2Dstyle%3A%20none%3B%0A%7D%0Atable%20thead%2C%20table%20tr%2Eeven%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Ap%20%7B%0Amargin%3A%200%2E5em%200%3B%0A%7D%0Ablockquote%20%7B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Apadding%3A%200%2E25em%200%2E75em%3B%0A%7D%0Ahr%20%7B%0Aborder%2Dstyle%3A%20solid%3B%0Aborder%3A%20none%3B%0Aborder%2Dtop%3A%201px%20solid%20%23777%3B%0Amargin%3A%2028px%200%3B%0A%7D%0Adl%20%7B%0Amargin%2Dleft%3A%200%3B%0A%7D%0Adl%20dd%20%7B%0Amargin%2Dbottom%3A%2013px%3B%0Amargin%2Dleft%3A%2013px%3B%0A%7D%0Adl%20dt%20%7B%0Afont%2Dweight%3A%20bold%3B%0A%7D%0Aul%20%7B%0Amargin%2Dtop%3A%200%3B%0A%7D%0Aul%20li%20%7B%0Alist%2Dstyle%3A%20circle%20outside%3B%0A%7D%0Aul%20ul%20%7B%0Amargin%2Dbottom%3A%200%3B%0A%7D%0Apre%2C%20code%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0Aborder%2Dradius%3A%203px%3B%0Acolor%3A%20%23333%3B%0Awhite%2Dspace%3A%20pre%2Dwrap%3B%20%0A%7D%0Apre%20%7B%0Aborder%2Dradius%3A%203px%3B%0Amargin%3A%205px%200px%2010px%200px%3B%0Apadding%3A%2010px%3B%0A%7D%0Apre%3Anot%28%5Bclass%5D%29%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Acode%20%7B%0Afont%2Dfamily%3A%20Consolas%2C%20Monaco%2C%20%27Courier%20New%27%2C%20monospace%3B%0Afont%2Dsize%3A%2085%25%3B%0A%7D%0Ap%20%3E%20code%2C%20li%20%3E%20code%20%7B%0Apadding%3A%202px%200px%3B%0A%7D%0Adiv%2Efigure%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0Aimg%20%7B%0Abackground%2Dcolor%3A%20%23FFFFFF%3B%0Apadding%3A%202px%3B%0Aborder%3A%201px%20solid%20%23DDDDDD%3B%0Aborder%2Dradius%3A%203px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Amargin%3A%200%205px%3B%0A%7D%0Ah1%20%7B%0Amargin%2Dtop%3A%200%3B%0Afont%2Dsize%3A%2035px%3B%0Aline%2Dheight%3A%2040px%3B%0A%7D%0Ah2%20%7B%0Aborder%2Dbottom%3A%204px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Apadding%2Dbottom%3A%202px%3B%0Afont%2Dsize%3A%20145%25%3B%0A%7D%0Ah3%20%7B%0Aborder%2Dbottom%3A%202px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Afont%2Dsize%3A%20120%25%3B%0A%7D%0Ah4%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23f7f7f7%3B%0Amargin%2Dleft%3A%208px%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Ah5%2C%20h6%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23ccc%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Aa%20%7B%0Acolor%3A%20%230033dd%3B%0Atext%2Ddecoration%3A%20none%3B%0A%7D%0Aa%3Ahover%20%7B%0Acolor%3A%20%236666ff%3B%20%7D%0Aa%3Avisited%20%7B%0Acolor%3A%20%23800080%3B%20%7D%0Aa%3Avisited%3Ahover%20%7B%0Acolor%3A%20%23BB00BB%3B%20%7D%0Aa%5Bhref%5E%3D%22http%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0Aa%5Bhref%5E%3D%22https%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0A%0Acode%20%3E%20span%2Ekw%20%7B%20color%3A%20%23555%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Edt%20%7B%20color%3A%20%23902000%3B%20%7D%20%0Acode%20%3E%20span%2Edv%20%7B%20color%3A%20%2340a070%3B%20%7D%20%0Acode%20%3E%20span%2Ebn%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Efl%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Ech%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Est%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Eco%20%7B%20color%3A%20%23888888%3B%20font%2Dstyle%3A%20italic%3B%20%7D%20%0Acode%20%3E%20span%2Eot%20%7B%20color%3A%20%23007020%3B%20%7D%20%0Acode%20%3E%20span%2Eal%20%7B%20color%3A%20%23ff0000%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Efu%20%7B%20color%3A%20%23900%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%20code%20%3E%20span%2Eer%20%7B%20color%3A%20%23a61717%3B%20background%2Dcolor%3A%20%23e3d2d2%3B%20%7D%20%0A" rel="stylesheet" type="text/css" />




</head>

<body>




<h1 class="title toc-ignore">Discriminant Analysis for Matrix Variate Distributions</h1>
<h4 class="author">Geoffrey Thompson</h4>
<h4 class="date">2019-11-14</h4>



<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(MixMatrix)</code></pre></div>
<p>In the <code>MixMatrix</code> package, there are two functions for training a linear or quadratic classifier. The usage is fairly similar to the function <code>MASS::lda()</code> or <code>MASS::qda()</code>, however it requires the input as an array and the group variable provided as a vector (that is, it cannot handle data frames or the formula interface directly, which is reasonable, as there is no immediately clear way to make that work for a collection of matrices).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">20180222</span>)
<span class="kw">library</span>(<span class="st">'MixMatrix'</span>)
A &lt;-<span class="st"> </span><span class="kw">rmatrixnorm</span>(<span class="dv">30</span>, <span class="dt">mean =</span> <span class="kw">matrix</span>(<span class="dv">0</span>, <span class="dt">nrow=</span><span class="dv">2</span>, <span class="dt">ncol=</span><span class="dv">3</span>)) <span class="co"># creating the three groups</span>
B &lt;-<span class="st"> </span><span class="kw">rmatrixnorm</span>(<span class="dv">30</span>, <span class="dt">mean =</span> <span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">0</span>), <span class="dt">nrow=</span><span class="dv">2</span>, <span class="dt">ncol=</span><span class="dv">3</span>))
C &lt;-<span class="st"> </span><span class="kw">rmatrixnorm</span>(<span class="dv">30</span>, <span class="dt">mean =</span> <span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">1</span>), <span class="dt">nrow=</span><span class="dv">2</span>, <span class="dt">ncol=</span><span class="dv">3</span>))
ABC &lt;-<span class="st"> </span><span class="kw">array</span>(<span class="kw">c</span>(A,B,C), <span class="dt">dim =</span> <span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">90</span>)) <span class="co"># combining into on array</span>
groups &lt;-<span class="st"> </span><span class="kw">factor</span>(<span class="kw">c</span>(<span class="kw">rep</span>(<span class="st">&quot;A&quot;</span>,<span class="dv">30</span>),<span class="kw">rep</span>(<span class="st">&quot;B&quot;</span>,<span class="dv">30</span>),<span class="kw">rep</span>(<span class="st">&quot;C&quot;</span>,<span class="dv">30</span>))) <span class="co"># labels</span>
prior =<span class="st"> </span><span class="kw">c</span>(<span class="dv">30</span>,<span class="dv">30</span>,<span class="dv">30</span>)<span class="op">/</span><span class="dv">90</span> <span class="co"># equal prior</span>
matlda &lt;-<span class="st"> </span><span class="kw">matrixlda</span>(<span class="dt">x =</span> ABC,<span class="dt">grouping =</span> groups, <span class="dt">prior =</span> prior) <span class="co"># perform LDA</span>
matqda &lt;-<span class="st"> </span><span class="kw">matrixqda</span>(<span class="dt">x =</span> ABC,<span class="dt">grouping =</span> groups, <span class="dt">prior =</span> prior) <span class="co"># perform QDA</span></code></pre></div>
<p>This does not sphere the data or extract an SVD or Fisher discriminant scores - it is a simple linear/quadratic discriminant function based on the likelihood function.</p>
<p>The <code>matrixlda</code> function presumes equal covariance matrices among the groups while <code>matrixqda</code> fits separate covariance for each groups.</p>
<p>It is possible to set variance or mean restrictions from the <code>MLmatrixnorm</code> and <code>MLmatrixt</code> functions using the <code>...</code> argument. These restrictions are applied to all groups.</p>
<p>The <code>predict</code> method for these objects works in much the same way as for <code>lda</code> or <code>qda</code> objects: provide the function and the new data, then it will return the MAP class assignments and the posterior. If no new data is provided, it will attempt to run it on the original data if it is available in the environment.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ABC[,,<span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">31</span>,<span class="dv">61</span>)] <span class="co"># true class memberships: A, B, C</span>
<span class="co">#&gt; , , 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;             [,1]       [,2]      [,3]</span>
<span class="co">#&gt; [1,] -0.07020924  0.8559433 0.9827602</span>
<span class="co">#&gt; [2,]  1.30097854 -0.6893054 0.2830575</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; , , 2</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;           [,1]     [,2]        [,3]</span>
<span class="co">#&gt; [1,] 2.2374662 2.408268 -0.37053822</span>
<span class="co">#&gt; [2,] 0.9653824 0.630897 -0.08850761</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; , , 3</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;            [,1]       [,2]      [,3]</span>
<span class="co">#&gt; [1,] -1.6961217 -1.5642705 0.2045711</span>
<span class="co">#&gt; [2,]  0.7782369  0.1842012 0.3869149</span>
<span class="co">#predict the membership of the first observation of each group</span>
<span class="kw">predict</span>(matlda, ABC[,,<span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">31</span>,<span class="dv">61</span>)]) 
<span class="co">#&gt; $class</span>
<span class="co">#&gt; [1] B B A</span>
<span class="co">#&gt; Levels: A B C</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $posterior</span>
<span class="co">#&gt;            [,1]        [,2]       [,3]</span>
<span class="co">#&gt; [1,] 0.27340107 0.690217317 0.03638161</span>
<span class="co">#&gt; [2,] 0.03833953 0.949049289 0.01261118</span>
<span class="co">#&gt; [3,] 0.54647035 0.001273576 0.45225607</span>
<span class="co">#predict the membership of the first observation of each group</span>
<span class="kw">predict</span>(matqda,  ABC[,,<span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">31</span>,<span class="dv">61</span>)])
<span class="co">#&gt; $class</span>
<span class="co">#&gt; [1] B B A</span>
<span class="co">#&gt; Levels: A B C</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $posterior</span>
<span class="co">#&gt;            [,1]        [,2]       [,3]</span>
<span class="co">#&gt; [1,] 0.24302341 0.735815885 0.02116070</span>
<span class="co">#&gt; [2,] 0.03295848 0.963641160 0.00340036</span>
<span class="co">#&gt; [3,] 0.54611977 0.007871269 0.44600896</span></code></pre></div>
<p>In this example, points from classes A, B, and C were selected and they ended up being classified as B, B, and A. The QDA and LDA rules had only minor disagreements, which is to be expected when they do truly have the same covariances.</p>
<div id="details-of-the-modeling-choices" class="section level2">
<h2>Details of the modeling choices</h2>
<p>Suppose there are two populations, <span class="math inline">\(\pi_1\)</span> and <span class="math inline">\(\pi_2\)</span> with prior probabilities of belonging to these classes, <span class="math inline">\(p_1\)</span> and <span class="math inline">\(p_2\)</span>. Define a function, <span class="math inline">\(c(1|2)\)</span> as the cost of misclassifying a member of population <span class="math inline">\(\pi_2\)</span> as a member of class <span class="math inline">\(1\)</span> (and vice versa). Further, define <span class="math inline">\(P(1|2)\)</span> as the probability of classifying a member of population <span class="math inline">\(\pi_2\)</span> as a member of class <span class="math inline">\(1\)</span> (and vice versa). Then we define the <em>expected cost of misclassification</em> as:</p>
<p><span class="math display">\[ECM = c(2|1)P(2|1)p_1 + c(1|2)P(1|2)p_2 \]</span></p>
</div>
<div id="classification-rule" class="section level2">
<h2>Classification Rule</h2>
<p>A reasonable classification rule based on ECM is the following:</p>
<p>Classify as class <span class="math inline">\(1\)</span> if:</p>
<p><span class="math display">\[ \frac{f_1(x)}{f_2(x)} \geq \frac{c(1|2) p_2}{c(2|1)p_1} \]</span></p>
<p>Where <span class="math inline">\(f_i(x)\)</span> is the probability density function for group <span class="math inline">\(\pi_i\)</span> evaluated at <span class="math inline">\(x\)</span>.</p>
</div>
<div id="matrix-variate-normal-populations" class="section level2">
<h2>Matrix Variate Normal Populations</h2>
<p>Recall the probability density function for a matrix variate normal distribution:</p>
<p><span class="math display">\[f(\mathbf{X};\mathbf{M}, \mathbf{U}, \mathbf{V}) = \frac{\exp\left( -\frac{1}{2} \, \mathrm{tr}\left[ \mathbf{V}^{-1} (\mathbf{X} - \mathbf{M})^{T} \mathbf{U}^{-1} (\mathbf{X} - \mathbf{M}) \right] \right)}{(2\pi)^{np/2} |\mathbf{V}|^{n/2} |\mathbf{U}|^{p/2}} \]</span></p>
<p><span class="math inline">\(\mathbf{X}\)</span> and <span class="math inline">\(\mathbf{M}\)</span> are <span class="math inline">\(n \times p\)</span>, <span class="math inline">\(\mathbf{U}\)</span> is <span class="math inline">\(n \times n\)</span> and describes the covariance relationship between the rows, and <span class="math inline">\(\mathbf{V}\)</span> is <span class="math inline">\(p \times p\)</span> and describes the covariance relationship between the columns.</p>
</div>
<div id="estimated-minimum-ecm-rule-for-two-matrix-variate-normal-populations" class="section level2">
<h2>Estimated Minimum ECM Rule for Two Matrix Variate Normal Populations</h2>
<p>A decision rule for this case:</p>
<span class="math display">\[\begin{eqnarray} 
R(\mathbf{X}) &amp; = &amp; \mathrm{trace}\big[ -\frac{1}{2}(\mathbf{V}_1^{-1} \mathbf{X}^{T} \mathbf{U}_1^{-1} \mathbf{X} - \mathbf{V}_2^{-1} \mathbf{X}^{T} \mathbf{U}_2^{-1} \mathbf{X}) \\
 &amp;  &amp; +(\mathbf{V}_1^{-1} \mathbf{M}_1^{T} \mathbf{U}_1^{-1} - \mathbf{V}_2^{-1} \mathbf{M}_2^{T} \mathbf{U}_2^{-1}) \mathbf{X} \\
 &amp;  &amp; -\frac{1}{2}(\mathbf{V}_1^{-1} \mathbf{M}_1^{T} \mathbf{U}_1^{-1} \mathbf{M}_1 - \mathbf{V}_2^{-1} \mathbf{M}_2^{T} \mathbf{U}_2^{-1} \mathbf{M}_2) \big]   \\ 
 &amp;  &amp; -\frac{1}{2}(p (\log|\mathbf{U}_1|-\log|\mathbf{U}_2|)+ n(\log|\mathbf{V}_1|-\log|\mathbf{V}_2|) )   
\end{eqnarray}\]</span>
</div>
<div id="how-to-classify-based-on-this" class="section level2">
<h2>How to classify based on this:</h2>
<p>If <span class="math inline">\(R(\mathbf{X}) \geq \log(c(1|2)p_2) - \log(c(2|1)p_1)\)</span>, assign <span class="math inline">\(\mathbf{X}\)</span> to group <span class="math inline">\(1\)</span>, otherwise assign to group <span class="math inline">\(2\)</span>.</p>
<p>In the multivariate case, this is equivalent to the LDA/QDA rules - term (1) is the quadratic form which vanishes in case of equal covariances between groups, term (2) is the LDA term, and terms (3) and (4) are constants which depend on the parameters and not <span class="math inline">\(\mathrm{X}\)</span>.</p>
<p>Typically, the models we have used have implicitly used an equal probability prior and an equal cost of misclassification, but other inputs can be specified. In case of equal priors and equal cost of misclassification, this term is 0.</p>
</div>
<div id="if-there-are-equal-covariances" class="section level2">
<h2>If there are equal covariances:</h2>
If the two groups have the same covariances, then this simplifies. The classification rule is then:
<span class="math display">\[\begin{eqnarray} 
R(\mathbf{X}) &amp; = &amp; \mathrm{trace}\big[ (\mathbf{V}^{-1} (\mathbf{M}_1 -\mathbf{M}_2)^{T}\mathbf{U}^{-1}) \mathbf{X} \\
 &amp;  &amp; -\frac{1}{2}(\mathbf{V}^{-1} \mathbf{M}_1^{T} \mathbf{U}^{-1} \mathbf{M}_1 - \mathbf{V}^{-1} \mathbf{M}_2^{T} \mathbf{U}^{-1} \mathbf{M}_2) \big]    \\ 
   &amp; \geq &amp; \log(c(1|2)p_2) - \log(c(2|1)p_1)
\end{eqnarray}\]</span>
<p>Classify to group <span class="math inline">\(1\)</span> if the last term is true. Note this is linear in <span class="math inline">\(\mathbf{X}\)</span>. This is directly analogous to LDA in the multivariate case.</p>
</div>
<div id="generalizing-to-multiple-classes" class="section level2">
<h2>Generalizing to multiple classes</h2>
<p>The factor <span class="math inline">\(R\)</span> for each group <span class="math inline">\(g\)</span> in a QDA setting is:</p>
<span class="math display">\[\begin{eqnarray} 
R_g(\mathbf{X}) &amp; = &amp; \mathrm{trace}\big[ -\frac{1}{2}(\mathbf{V}_g^{-1} \mathbf{X}^{T} \mathbf{U}_g^{-1} \mathbf{X}  +(\mathbf{V}_g^{-1} \mathbf{M}_g^{T} \mathbf{U}_g^{-1}) \mathbf{X}  -\frac{1}{2}(\mathbf{V}_g^{-1} \mathbf{M}_g^{T} \mathbf{U}_g^{-1} \mathbf{M}_g)  \big]   \\ 
 &amp;  &amp; -\frac{1}{2}(p (\log|\mathbf{U}_g|)+ n(\log|\mathbf{V}_g|) )  + \log p_g 
\end{eqnarray}\]</span>
<p>When <span class="math inline">\(U_i = U_j\)</span> for all groups <span class="math inline">\(i,j\)</span>, several of these terms cancel. The posterior probability is:</p>
<p><span class="math display">\[ P(\mathbf{X} \in g) = \frac{ \exp (R_g (\mathbf{X}))}{\sum_i \exp (R_i(\mathbf{X}))} \]</span> with the bottom sum being over all groups <span class="math inline">\(i\)</span>.</p>
</div>
<div id="structure-of-the-objects" class="section level2">
<h2>Structure of the objects</h2>
<p>The objects returned by <code>matrixlda</code> and <code>matrixqda</code> are S3 classes. See below example output:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">matlda
<span class="co">#&gt; $prior</span>
<span class="co">#&gt;         A         B         C </span>
<span class="co">#&gt; 0.3333333 0.3333333 0.3333333 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $counts</span>
<span class="co">#&gt;  A  B  C </span>
<span class="co">#&gt; 30 30 30 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $means</span>
<span class="co">#&gt; , , 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;            [,1]        [,2]       [,3]</span>
<span class="co">#&gt; [1,] 0.08629672 -0.06362916 -0.3045685</span>
<span class="co">#&gt; [2,] 0.03851982 -0.01375580  0.3978759</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; , , 2</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;           [,1]       [,2]       [,3]</span>
<span class="co">#&gt; [1,] 1.2872487  1.1199220 1.01282774</span>
<span class="co">#&gt; [2,] 0.3044151 -0.3797203 0.06539076</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; , , 3</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;            [,1]       [,2]       [,3]</span>
<span class="co">#&gt; [1,] 0.07377351 -0.3278233 -0.3031961</span>
<span class="co">#&gt; [2,] 0.92568372  1.3738475  0.9353985</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $scaling</span>
<span class="co">#&gt; [1] 1.002299</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $U</span>
<span class="co">#&gt;            [,1]       [,2]</span>
<span class="co">#&gt; [1,] 1.00000000 0.03243759</span>
<span class="co">#&gt; [2,] 0.03243759 0.97819549</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $V</span>
<span class="co">#&gt;             [,1]        [,2]        [,3]</span>
<span class="co">#&gt; [1,]  1.00000000  0.01988966 -0.04879263</span>
<span class="co">#&gt; [2,]  0.01988966  0.93839973 -0.04563610</span>
<span class="co">#&gt; [3,] -0.04879263 -0.04563610  0.93321444</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $lev</span>
<span class="co">#&gt; [1] &quot;A&quot; &quot;B&quot; &quot;C&quot;</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $N</span>
<span class="co">#&gt; [1] 90</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $method</span>
<span class="co">#&gt; [1] &quot;normal&quot;</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $nu</span>
<span class="co">#&gt; NULL</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $call</span>
<span class="co">#&gt; matrixlda(x = ABC, grouping = groups, prior = prior)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; attr(,&quot;class&quot;)</span>
<span class="co">#&gt; [1] &quot;matrixlda&quot;</span>

matqda
<span class="co">#&gt; $prior</span>
<span class="co">#&gt;         A         B         C </span>
<span class="co">#&gt; 0.3333333 0.3333333 0.3333333 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $counts</span>
<span class="co">#&gt;  A  B  C </span>
<span class="co">#&gt; 30 30 30 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $means</span>
<span class="co">#&gt; , , 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;            [,1]        [,2]       [,3]</span>
<span class="co">#&gt; [1,] 0.08629672 -0.06362916 -0.3045685</span>
<span class="co">#&gt; [2,] 0.03851982 -0.01375580  0.3978759</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; , , 2</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;           [,1]       [,2]       [,3]</span>
<span class="co">#&gt; [1,] 1.2872487  1.1199220 1.01282774</span>
<span class="co">#&gt; [2,] 0.3044151 -0.3797203 0.06539076</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; , , 3</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;            [,1]       [,2]       [,3]</span>
<span class="co">#&gt; [1,] 0.07377351 -0.3278233 -0.3031961</span>
<span class="co">#&gt; [2,] 0.92568372  1.3738475  0.9353985</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $U</span>
<span class="co">#&gt; , , 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;            [,1]       [,2]</span>
<span class="co">#&gt; [1,] 1.00000000 0.02620514</span>
<span class="co">#&gt; [2,] 0.02620514 0.95989647</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; , , 2</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;            [,1]       [,2]</span>
<span class="co">#&gt; [1,]  1.0000000 -0.0173514</span>
<span class="co">#&gt; [2,] -0.0173514  0.9456145</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; , , 3</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;          [,1]     [,2]</span>
<span class="co">#&gt; [1,] 1.000000 0.129851</span>
<span class="co">#&gt; [2,] 0.129851 1.061265</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $V</span>
<span class="co">#&gt; , , 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;             [,1]        [,2]        [,3]</span>
<span class="co">#&gt; [1,]  1.05498245 -0.07418973  0.09476411</span>
<span class="co">#&gt; [2,] -0.07418973  0.98800103 -0.04390729</span>
<span class="co">#&gt; [3,]  0.09476411 -0.04390729  0.79903040</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; , , 2</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;             [,1]       [,2]        [,3]</span>
<span class="co">#&gt; [1,]  1.09941477 0.12678075 -0.03952663</span>
<span class="co">#&gt; [2,]  0.12678075 0.94606849  0.03910645</span>
<span class="co">#&gt; [3,] -0.03952663 0.03910645  0.85913748</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; , , 3</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;              [,1]         [,2]       [,3]</span>
<span class="co">#&gt; [1,]  0.833193637  0.008466708 -0.2084547</span>
<span class="co">#&gt; [2,]  0.008466708  0.875328749 -0.1142510</span>
<span class="co">#&gt; [3,] -0.208454704 -0.114250988  1.1520533</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $lev</span>
<span class="co">#&gt; [1] &quot;A&quot; &quot;B&quot; &quot;C&quot;</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $N</span>
<span class="co">#&gt; [1] 90</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $method</span>
<span class="co">#&gt; [1] &quot;normal&quot;</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $nu</span>
<span class="co">#&gt; NULL</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $call</span>
<span class="co">#&gt; matrixqda(x = ABC, grouping = groups, prior = prior)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; attr(,&quot;class&quot;)</span>
<span class="co">#&gt; [1] &quot;matrixqda&quot;</span></code></pre></div>
</div>
<div id="session-info" class="section level2">
<h2>Session info</h2>
<p>This vignette was built using <code>rmarkdown</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sessionInfo</span>()
<span class="co">#&gt; R version 3.6.1 (2019-07-05)</span>
<span class="co">#&gt; Platform: x86_64-redhat-linux-gnu (64-bit)</span>
<span class="co">#&gt; Running under: Fedora 30 (Thirty)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Matrix products: default</span>
<span class="co">#&gt; BLAS/LAPACK: /usr/lib64/R/lib/libRblas.so</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; locale:</span>
<span class="co">#&gt;  [1] LC_CTYPE=en_US.utf8       LC_NUMERIC=C             </span>
<span class="co">#&gt;  [3] LC_TIME=en_US.utf8        LC_COLLATE=C             </span>
<span class="co">#&gt;  [5] LC_MONETARY=en_US.utf8    LC_MESSAGES=en_US.utf8   </span>
<span class="co">#&gt;  [7] LC_PAPER=en_US.utf8       LC_NAME=C                </span>
<span class="co">#&gt;  [9] LC_ADDRESS=C              LC_TELEPHONE=C           </span>
<span class="co">#&gt; [11] LC_MEASUREMENT=en_US.utf8 LC_IDENTIFICATION=C      </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; attached base packages:</span>
<span class="co">#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; other attached packages:</span>
<span class="co">#&gt; [1] MixMatrix_0.2.4</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; loaded via a namespace (and not attached):</span>
<span class="co">#&gt;  [1] compiler_3.6.1  magrittr_1.5    htmltools_0.4.0 tools_3.6.1    </span>
<span class="co">#&gt;  [5] yaml_2.2.0      Rcpp_1.0.3      stringi_1.4.3   rmarkdown_1.16 </span>
<span class="co">#&gt;  [9] knitr_1.25      stringr_1.4.0   digest_0.6.22   xfun_0.10      </span>
<span class="co">#&gt; [13] rlang_0.4.0     evaluate_0.14</span></code></pre></div>
</div>
<div id="all-the-code-for-easy-copying" class="section level2">
<h2>All the code for easy copying</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">knitr<span class="op">::</span>opts_chunk<span class="op">$</span><span class="kw">set</span>(
  <span class="dt">collapse =</span> <span class="ot">TRUE</span>,
  <span class="dt">comment =</span> <span class="st">&quot;#&gt;&quot;</span>
)
<span class="kw">set.seed</span>(<span class="dv">20180222</span>)
<span class="kw">library</span>(<span class="st">'MixMatrix'</span>)
A &lt;-<span class="st"> </span><span class="kw">rmatrixnorm</span>(<span class="dv">30</span>, <span class="dt">mean =</span> <span class="kw">matrix</span>(<span class="dv">0</span>, <span class="dt">nrow=</span><span class="dv">2</span>, <span class="dt">ncol=</span><span class="dv">3</span>)) <span class="co"># creating the three groups</span>
B &lt;-<span class="st"> </span><span class="kw">rmatrixnorm</span>(<span class="dv">30</span>, <span class="dt">mean =</span> <span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">0</span>), <span class="dt">nrow=</span><span class="dv">2</span>, <span class="dt">ncol=</span><span class="dv">3</span>))
C &lt;-<span class="st"> </span><span class="kw">rmatrixnorm</span>(<span class="dv">30</span>, <span class="dt">mean =</span> <span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">1</span>), <span class="dt">nrow=</span><span class="dv">2</span>, <span class="dt">ncol=</span><span class="dv">3</span>))
ABC &lt;-<span class="st"> </span><span class="kw">array</span>(<span class="kw">c</span>(A,B,C), <span class="dt">dim =</span> <span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">90</span>)) <span class="co"># combining into on array</span>
groups &lt;-<span class="st"> </span><span class="kw">factor</span>(<span class="kw">c</span>(<span class="kw">rep</span>(<span class="st">&quot;A&quot;</span>,<span class="dv">30</span>),<span class="kw">rep</span>(<span class="st">&quot;B&quot;</span>,<span class="dv">30</span>),<span class="kw">rep</span>(<span class="st">&quot;C&quot;</span>,<span class="dv">30</span>))) <span class="co"># labels</span>
prior =<span class="st"> </span><span class="kw">c</span>(<span class="dv">30</span>,<span class="dv">30</span>,<span class="dv">30</span>)<span class="op">/</span><span class="dv">90</span> <span class="co"># equal prior</span>
matlda &lt;-<span class="st"> </span><span class="kw">matrixlda</span>(<span class="dt">x =</span> ABC,<span class="dt">grouping =</span> groups, <span class="dt">prior =</span> prior) <span class="co"># perform LDA</span>
matqda &lt;-<span class="st"> </span><span class="kw">matrixqda</span>(<span class="dt">x =</span> ABC,<span class="dt">grouping =</span> groups, <span class="dt">prior =</span> prior) <span class="co"># perform QDA</span>
ABC[,,<span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">31</span>,<span class="dv">61</span>)] <span class="co"># true class memberships: A, B, C</span>
<span class="co">#predict the membership of the first observation of each group</span>
<span class="kw">predict</span>(matlda, ABC[,,<span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">31</span>,<span class="dv">61</span>)]) 
<span class="co">#predict the membership of the first observation of each group</span>
<span class="kw">predict</span>(matqda,  ABC[,,<span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">31</span>,<span class="dv">61</span>)])

matlda

matqda

<span class="kw">sessionInfo</span>()</code></pre></div>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
