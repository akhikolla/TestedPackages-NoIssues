<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />

<meta name="author" content="Robert W Schlegel and AJ Smit" />

<meta name="date" content="2020-06-27" />

<title>Downloading and Preparing NOAA OISST Data</title>

<script>// Hide empty <a> tag within highlighted CodeBlock for screen reader accessibility (see https://github.com/jgm/pandoc/issues/6352#issuecomment-626106786) -->
// v0.0.1
// Written by JooYoung Seo (jooyoung@psu.edu) and Atsushi Yasumoto on June 1st, 2020.

document.addEventListener('DOMContentLoaded', function() {
  const codeList = document.getElementsByClassName("sourceCode");
  for (var i = 0; i < codeList.length; i++) {
    var linkList = codeList[i].getElementsByTagName('a');
    for (var j = 0; j < linkList.length; j++) {
      if (linkList[j].innerHTML === "") {
        linkList[j].setAttribute('aria-hidden', 'true');
      }
    }
  }
});
</script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    for (var j = 0; j < rules.length; j++) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") continue;
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') continue;
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>



<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Downloading and Preparing NOAA OISST Data</h1>
<h4 class="author">Robert W Schlegel and AJ Smit</h4>
<h4 class="date">2020-06-27</h4>



<div id="overview" class="section level2">
<h2>Overview</h2>
<p>In this vignette we will see how to retrieve and prepare <a href="https://journals.ametsoc.org/doi/full/10.1175/2007JCLI1824.1">Reynolds optimally interpolated sea surface temperature</a> (OISST) data for calculating marine heatwaves (MHWs). The OISST product is a global 1/4 degree gridded dataset of Advanced Very High Resolution Radiometer (AVHRR) derived SSTs at a daily resolution, starting on 1 September 1981. The source of the data is currently the <a href="https://www.ncdc.noaa.gov/oisst">NOAA NCDC</a>.</p>
<p>Each daily global file, when not compressed, is around 8.3 MB, so they add up to a large amount of data when a time series of the recommended 30 year minimum duration for the detection of MHWs is downloaded. If one were to download all of the data currently available it would exceed 100 GB of total disk space. It is therefore best practice to download only a subset of the data that matches oneâ€™s study area. Thanks to the <a href="https://docs.ropensci.org/rerddap/"><strong><code>rerddap</code></strong> package</a> this is incredibly easy to do in <code>R</code>.</p>
<p>Should one want to download the full global dataset, each daily global file is available in netCDF format and is roughly 1.6 MB. This means that one full year of global data will be roughly 600 MB, and the full dataset roughly 25 GB. This is however when the data are very compressed. If we were to attempt to load the entire uncompressed dataset into our memory at once it would take more than 200 GB of RAM. That is well beyond the scope of any current laptop so in the second half of this vignette we will see how to download the full OISST dataset before then seeing how we can load only a subset of the data into the R environment for use with further analyses.</p>
<p>This vignette may appear very long and complex but it has been written in an attempt to keep the process of downloading and working with satellite data as straight-forward and easy to follow as possible. Before we begin with all of the code etc. please note that for almost all applications it is only necessary to use the first method outlined below. For most users the second download method in this vignette can simply be skipped.</p>
</div>
<div id="setup" class="section level2">
<h2>Setup</h2>
<p>For this vignette we will be accessing the NOAA OISST dataset on this <a href="https://coastwatch.pfeg.noaa.gov/erddap/griddap/NOAA_DHW.html">ERDDAP server</a> for the subsetted data, while the global data are indexed <a href="https://www.ncei.noaa.gov/data/sea-surface-temperature-optimum-interpolation/v2.1/access/avhrr/">here</a>. One may download the data on both servers manually by using the ERDDAP UI or clicking on each indexed file individually. But programming languages like R are designed to prevent us from needing to experience that sort of anguish. Below we will load the libraries we need in order to have R download all of the data that we may need. If any of the lines of code in the following chunk do not run it means that we will need to first install that package. Uncomment the line of code that would install the problem package and run it before trying to load the library again.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1"></a><span class="co"># The packages we will need</span></span>
<span id="cb1-2"><a href="#cb1-2"></a><span class="co"># install.packages(&quot;dplyr&quot;)</span></span>
<span id="cb1-3"><a href="#cb1-3"></a><span class="co"># install.packages(&quot;lubridate&quot;)</span></span>
<span id="cb1-4"><a href="#cb1-4"></a><span class="co"># install.packages(&quot;ggplot2&quot;)</span></span>
<span id="cb1-5"><a href="#cb1-5"></a><span class="co"># install.packages(&quot;tidync&quot;)</span></span>
<span id="cb1-6"><a href="#cb1-6"></a><span class="co"># install.packages(&quot;doParallel&quot;)</span></span>
<span id="cb1-7"><a href="#cb1-7"></a><span class="co"># install.packages(&quot;rerddap&quot;)</span></span>
<span id="cb1-8"><a href="#cb1-8"></a><span class="co"># install.packages(&quot;plyr&quot;) # Note that this library should never be loaded, only installed</span></span>
<span id="cb1-9"><a href="#cb1-9"></a></span>
<span id="cb1-10"><a href="#cb1-10"></a><span class="co"># The packages we will use</span></span>
<span id="cb1-11"><a href="#cb1-11"></a><span class="kw">library</span>(dplyr) <span class="co"># A staple for modern data management in R</span></span>
<span id="cb1-12"><a href="#cb1-12"></a><span class="kw">library</span>(lubridate) <span class="co"># Useful functions for dealing with dates</span></span>
<span id="cb1-13"><a href="#cb1-13"></a><span class="kw">library</span>(ggplot2) <span class="co"># The preferred library for data visualisation</span></span>
<span id="cb1-14"><a href="#cb1-14"></a><span class="kw">library</span>(tidync) <span class="co"># For easily dealing with NetCDF data</span></span>
<span id="cb1-15"><a href="#cb1-15"></a><span class="kw">library</span>(rerddap) <span class="co"># For easily downloading subsets of data</span></span>
<span id="cb1-16"><a href="#cb1-16"></a><span class="kw">library</span>(doParallel) <span class="co"># For parallel processing</span></span></code></pre></div>
<p>With our packages loaded we may now begin downloading and preparing our data for further use. Please use the table of contents on the right side of the screen to jump between the different download methods as desired. We will break each different method down into smaller steps in order to keep this process as clear as possible. Before we begin I need to stress that this is a very direct and unrestricted method for accessing these data and I urge responsibility in only downloading as much data as are necessary. Please do not download the entire dataset unless you have a specific need for it.</p>
</div>
<div id="downloading-subsetted-data" class="section level2">
<h2>Downloading subsetted data</h2>
<div id="file-information" class="section level3">
<h3>File information</h3>
<p>Before we begin downloading the subsetted data for our study area we need to make sure that they are currently available on an ERDDAP server. The location of the NOAA OISST data has changed in the past so it should not be assumed that the current location will exist in perpetuity. Finding the server on which these data are located can be a cup game at times.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1"></a><span class="co"># The information for the NOAA OISST data</span></span>
<span id="cb2-2"><a href="#cb2-2"></a>rerddap<span class="op">::</span><span class="kw">info</span>(<span class="dt">datasetid =</span> <span class="st">&quot;ncdcOisst21Agg_LonPM180&quot;</span>, <span class="dt">url =</span> <span class="st">&quot;https://coastwatch.pfeg.noaa.gov/erddap/&quot;</span>)</span>
<span id="cb2-3"><a href="#cb2-3"></a></span>
<span id="cb2-4"><a href="#cb2-4"></a><span class="co"># Note that there is also a version with lon values from 0 yo 360</span></span>
<span id="cb2-5"><a href="#cb2-5"></a>rerddap<span class="op">::</span><span class="kw">info</span>(<span class="dt">datasetid =</span> <span class="st">&quot;ncdcOisst21Agg&quot;</span>, <span class="dt">url =</span> <span class="st">&quot;https://coastwatch.pfeg.noaa.gov/erddap/&quot;</span>)</span></code></pre></div>
<p>With our target dataset identified we may now begin the download with the <code>griddap()</code> function. While putting this vignette together however I noticed one little hiccup in the work flow. It seems that the ERDDAP server does not like it when one tries to access more than nine consecutive years of data in one request, regardless of the spatial extent being requested. So before we download our data we are going to make a wrapper function that helps us control the range of times we want to download. This will reduce the amount of redundant coding we would otherwise need to do.</p>
</div>
<div id="download-function" class="section level3">
<h3>Download function</h3>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1"></a><span class="co"># This function downloads and prepares data based on user provided start and end dates</span></span>
<span id="cb3-2"><a href="#cb3-2"></a>OISST_sub_dl &lt;-<span class="st"> </span><span class="cf">function</span>(time_df){</span>
<span id="cb3-3"><a href="#cb3-3"></a>  OISST_dat &lt;-<span class="st"> </span><span class="kw">griddap</span>(<span class="dt">x =</span> <span class="st">&quot;ncdcOisst21Agg_LonPM180&quot;</span>, </span>
<span id="cb3-4"><a href="#cb3-4"></a>                       <span class="dt">url =</span> <span class="st">&quot;https://coastwatch.pfeg.noaa.gov/erddap/&quot;</span>, </span>
<span id="cb3-5"><a href="#cb3-5"></a>                       <span class="dt">time =</span> <span class="kw">c</span>(time_df<span class="op">$</span>start, time_df<span class="op">$</span>end), </span>
<span id="cb3-6"><a href="#cb3-6"></a>                       <span class="dt">zlev =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>),</span>
<span id="cb3-7"><a href="#cb3-7"></a>                       <span class="dt">latitude =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">40</span>, <span class="dv">-35</span>),</span>
<span id="cb3-8"><a href="#cb3-8"></a>                       <span class="dt">longitude =</span> <span class="kw">c</span>(<span class="dv">15</span>, <span class="dv">21</span>),</span>
<span id="cb3-9"><a href="#cb3-9"></a>                       <span class="dt">fields =</span> <span class="st">&quot;sst&quot;</span>)<span class="op">$</span>data <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb3-10"><a href="#cb3-10"></a><span class="st">    </span><span class="kw">mutate</span>(<span class="dt">time =</span> <span class="kw">as.Date</span>(stringr<span class="op">::</span><span class="kw">str_remove</span>(time, <span class="st">&quot;T00:00:00Z&quot;</span>))) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb3-11"><a href="#cb3-11"></a><span class="st">    </span>dplyr<span class="op">::</span><span class="kw">rename</span>(<span class="dt">t =</span> time, <span class="dt">temp =</span> sst) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb3-12"><a href="#cb3-12"></a><span class="st">    </span><span class="kw">select</span>(lon, lat, t, temp) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb3-13"><a href="#cb3-13"></a><span class="st">    </span><span class="kw">na.omit</span>()</span>
<span id="cb3-14"><a href="#cb3-14"></a>}</span></code></pre></div>
<p>In the wrapper function above we see that we have chosen to download only the â€˜sstâ€™ data out of the several variables (â€˜fieldsâ€™) available to us. We also see that we have chosen the spatial extent of latitude -40 to -35 and longitude 15 to 21. This a small window over some of the Agulhas Retroflection to the south west of South Africa. A larger area is not being chosen here simply due to the speed constraints of downloading the data and detecting the events therein. One may simply change the longitude and latitude values above as necessary to match the desired study area. The function will also be re-labelling the â€˜timeâ€™ column as â€˜tâ€™, and the â€˜sstâ€™ column as â€˜tempâ€™. We do this so that they match the default column names that are expected for calculating MHWs and we wonâ€™t have to do any extra work later on.</p>
<p>One must note here that depending on the RAM available on oneâ€™s machine, it may not be possible to handle all of the data downloaded at once if they are very large (e.g.Â &gt; 5 GB). The discussion on the limitations of the R language due to its dependence on virtual memory is beyond the scope of this vignette, but if one limits oneâ€™s downloads to no more than several square pixels at a time that should be fine. Were one to try to download the whole Indian Ocean, for example, that may cause issues if being run on a laptop or computer of a similar power.</p>
</div>
<div id="date-range" class="section level3">
<h3>Date range</h3>
<p>With our wrapper function written we would now need to run it several times in order to grab all of the OISST data from <code>1982-01-01</code> to <code>2019-12-31</code>. Even though each year of data for the extent used in this vignette is only ~360 KB, the server does not like it when more than 9 years of consecutive data are requested. The server will also end a users connection after ~17 individual files have been requested. Because we canâ€™t download all of the data in one request, and we canâ€™t download the data one year at a time, we will need to make requests for multiple batches of data. To accomplish this we will create a dataframe of start and end dates that will allow us to automate the entire download while meeting the aforementioned criteria.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1"></a><span class="co"># Date download range by start and end dates per year</span></span>
<span id="cb4-2"><a href="#cb4-2"></a>dl_years &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">date_index =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">5</span>,</span>
<span id="cb4-3"><a href="#cb4-3"></a>                       <span class="dt">start =</span> <span class="kw">as.Date</span>(<span class="kw">c</span>(<span class="st">&quot;1982-01-01&quot;</span>, <span class="st">&quot;1990-01-01&quot;</span>, </span>
<span id="cb4-4"><a href="#cb4-4"></a>                                         <span class="st">&quot;1998-01-01&quot;</span>, <span class="st">&quot;2006-01-01&quot;</span>, <span class="st">&quot;2014-01-01&quot;</span>)),</span>
<span id="cb4-5"><a href="#cb4-5"></a>                       <span class="dt">end =</span> <span class="kw">as.Date</span>(<span class="kw">c</span>(<span class="st">&quot;1989-12-31&quot;</span>, <span class="st">&quot;1997-12-31&quot;</span>, </span>
<span id="cb4-6"><a href="#cb4-6"></a>                                       <span class="st">&quot;2005-12-31&quot;</span>, <span class="st">&quot;2013-12-31&quot;</span>, <span class="st">&quot;2019-12-31&quot;</span>)))</span></code></pre></div>
</div>
<div id="downloadprep-data" class="section level3">
<h3>Download/prep data</h3>
<p>One could also use the <strong><code>plyr</code></strong> suite of functions to automate the process of downloading and processing multiple files, but Iâ€™ve chosen here to stick with the <strong><code>tidyverse</code></strong> native approach. If the below chunk of code fails or times out, simply re-run it until all of the data have been downloaded.</p>
<p>It is worth pointing out here that these data are downloaded as cached files on the users computer by using the <strong><code>hoardr</code></strong> package. This means that if one runs the same command again, it will not re-download the data because it first looks in the folder where it has automatically cached the data for you and sees that it may simply draw the data from there. No need to change anything or write a second script for loading data.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1"></a><span class="co"># Download all of the data with one nested request</span></span>
<span id="cb5-2"><a href="#cb5-2"></a><span class="co"># The time this takes will vary greatly based on connection speed</span></span>
<span id="cb5-3"><a href="#cb5-3"></a><span class="kw">system.time</span>(</span>
<span id="cb5-4"><a href="#cb5-4"></a>  OISST_data &lt;-<span class="st"> </span>dl_years <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb5-5"><a href="#cb5-5"></a><span class="st">    </span><span class="kw">group_by</span>(date_index) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb5-6"><a href="#cb5-6"></a><span class="st">    </span><span class="kw">group_modify</span>(<span class="op">~</span><span class="kw">OISST_sub_dl</span>(.x)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb5-7"><a href="#cb5-7"></a><span class="st">    </span><span class="kw">ungroup</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb5-8"><a href="#cb5-8"></a><span class="st">    </span><span class="kw">select</span>(lon, lat, t, temp)</span>
<span id="cb5-9"><a href="#cb5-9"></a>) <span class="co"># 636 seconds, ~127 seconds per batch</span></span></code></pre></div>
<p>If the above code chunk is giving errors it is likely due to oneâ€™s Internet connection timing out. There are also rare instances where the NOAA server is not responding due to an issue on their end. Any connection based issues may be resolved by simply waiting for a few minutes, or by ensuring a stable connection.</p>
</div>
<div id="visualise-data" class="section level3">
<h3>Visualise data</h3>
<p>Before we save our data for later use it is good practice to visualise them.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1"></a>OISST_data <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb6-2"><a href="#cb6-2"></a><span class="st">  </span><span class="kw">filter</span>(t <span class="op">==</span><span class="st"> &quot;2019-12-01&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb6-3"><a href="#cb6-3"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> lon, <span class="dt">y =</span> lat)) <span class="op">+</span></span>
<span id="cb6-4"><a href="#cb6-4"></a><span class="st">  </span><span class="kw">geom_tile</span>(<span class="kw">aes</span>(<span class="dt">fill =</span> temp)) <span class="op">+</span></span>
<span id="cb6-5"><a href="#cb6-5"></a><span class="st">  </span><span class="co"># borders() + # Activate this line to see the global map</span></span>
<span id="cb6-6"><a href="#cb6-6"></a><span class="st">  </span><span class="kw">scale_fill_viridis_c</span>() <span class="op">+</span></span>
<span id="cb6-7"><a href="#cb6-7"></a><span class="st">  </span><span class="kw">coord_quickmap</span>(<span class="dt">expand =</span> F) <span class="op">+</span></span>
<span id="cb6-8"><a href="#cb6-8"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="ot">NULL</span>, <span class="dt">y =</span> <span class="ot">NULL</span>, <span class="dt">fill =</span> <span class="st">&quot;SST (Â°C)&quot;</span>) <span class="op">+</span></span>
<span id="cb6-9"><a href="#cb6-9"></a><span class="st">  </span><span class="kw">theme</span>(<span class="dt">legend.position =</span> <span class="st">&quot;bottom&quot;</span>)</span></code></pre></div>
</div>
<div id="save-data" class="section level3">
<h3>Save data</h3>
<p>With the data downloaded and prepared for further use (and a test visual run), all thatâ€™s left to do is save them.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1"></a><span class="co"># Save the data as an .Rds file because it has a much better compression rate than .RData</span></span>
<span id="cb7-2"><a href="#cb7-2"></a><span class="kw">saveRDS</span>(OISST_data, <span class="dt">file =</span> <span class="st">&quot;~/Desktop/OISST_vignette.Rds&quot;</span>)</span></code></pre></div>
<p>Note above that I have chosen to save the file to my desktop. This is not normally where one (hopefully!) would save such a file. Rather one would be saving these data into the project folder out of which one is working. In the next vignette we will see how to <a href="https://robwschlegel.github.io/heatwaveR/articles/gridded_event_detection.html">detect MHWs in gridded data</a> using the data downloaded here.</p>
</div>
</div>
<div id="downloading-global-data" class="section level2">
<h2>Downloading global data</h2>
<p>The method for downloading and preparing NOAA OISST data outlined in the first half of this vignette should be considered best practice for all applications except those that specifically need to look at the entire globe. If one needs to download the global dataset then it is preferable to go straight to the source. Note that one may still download the full global dataset using the methods above by setting the lon/lat extent to be the full width and height of the globe. The method outlined below will download over 13,000 individual files. This makes dealing with individual files very easy, but agglomerating them into one file can be very time consuming.</p>
<div id="file-information-1" class="section level3">
<h3>File information</h3>
<p>The first step in downloading the full global dataset is to tell you computer where they are. There is an automated way to do this but it requires a couple of additional packages and we aim to keep this vignette as simple and direct as possible. For our purposes today we will manually create the URLs of the files we want to download.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1"></a><span class="co"># First we tell R where the data are on the interwebs</span></span>
<span id="cb8-2"><a href="#cb8-2"></a>OISST_base_url &lt;-<span class="st"> &quot;https://www.ncei.noaa.gov/data/sea-surface-temperature-optimum-interpolation/v2.1/access/avhrr/&quot;</span></span>
<span id="cb8-3"><a href="#cb8-3"></a><span class="co"># Note that one may go to this URL in any web browser to manually inspect the files</span></span>
<span id="cb8-4"><a href="#cb8-4"></a></span>
<span id="cb8-5"><a href="#cb8-5"></a><span class="co"># Now we create a data.frame that contains all of the dates we want to download</span></span>
<span id="cb8-6"><a href="#cb8-6"></a>  <span class="co"># NB: In order to change the dates download changes the dates in the following line</span></span>
<span id="cb8-7"><a href="#cb8-7"></a>OISST_dates &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">t =</span> <span class="kw">seq</span>(<span class="kw">as.Date</span>(<span class="st">&quot;2019-12-01&quot;</span>), <span class="kw">as.Date</span>(<span class="st">&quot;2019-12-31&quot;</span>), <span class="dt">by =</span> <span class="st">&quot;day&quot;</span>))</span>
<span id="cb8-8"><a href="#cb8-8"></a></span>
<span id="cb8-9"><a href="#cb8-9"></a><span class="co"># To finish up this step we add some text to those dates so they match the OISST file names</span></span>
<span id="cb8-10"><a href="#cb8-10"></a>OISST_files &lt;-<span class="st"> </span>OISST_dates <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb8-11"><a href="#cb8-11"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">t_day =</span> <span class="kw">gsub</span>(<span class="st">&quot;-&quot;</span>, <span class="st">&quot;&quot;</span>, t),</span>
<span id="cb8-12"><a href="#cb8-12"></a>         <span class="dt">t_month =</span> <span class="kw">substr</span>(t_day, <span class="dv">1</span>, <span class="dv">6</span>),</span>
<span id="cb8-13"><a href="#cb8-13"></a>         <span class="dt">t_year =</span> <span class="kw">year</span>(t),</span>
<span id="cb8-14"><a href="#cb8-14"></a>         <span class="dt">file_name =</span> <span class="kw">paste0</span>(OISST_base_url, t_month, <span class="st">&quot;/&quot;</span>, <span class="st">&quot;oisst-avhrr-v02r01.&quot;</span>, t_day ,<span class="st">&quot;.nc&quot;</span>))</span></code></pre></div>
</div>
<div id="download-data" class="section level3">
<h3>Download data</h3>
<p>Now that we have a dataframe that contains all of the URLs for the files we want to download weâ€™ll create a function that will crawl through those URLs and download the files for us.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1"></a><span class="co"># This function will go about downloading each day of data as a NetCDF file</span></span>
<span id="cb9-2"><a href="#cb9-2"></a><span class="co"># Note that this will download files into a &#39;data/OISST&#39; folder in the root directory</span></span>
<span id="cb9-3"><a href="#cb9-3"></a>  <span class="co"># If this folder does not exist it will create it</span></span>
<span id="cb9-4"><a href="#cb9-4"></a>  <span class="co"># If it does not automatically create the folder it will need to be done manually</span></span>
<span id="cb9-5"><a href="#cb9-5"></a>  <span class="co"># The folder that is created must be a new folder with no other files in it</span></span>
<span id="cb9-6"><a href="#cb9-6"></a>  <span class="co"># A possible bug with netCDF files in R is they won&#39;t load correctly from </span></span>
<span id="cb9-7"><a href="#cb9-7"></a>  <span class="co"># existing folders with other file types in them</span></span>
<span id="cb9-8"><a href="#cb9-8"></a><span class="co"># This function will also check if the file has been previously downloaded</span></span>
<span id="cb9-9"><a href="#cb9-9"></a>  <span class="co"># If it has it will not download it again</span></span>
<span id="cb9-10"><a href="#cb9-10"></a>OISST_url_daily_dl &lt;-<span class="st"> </span><span class="cf">function</span>(target_URL){</span>
<span id="cb9-11"><a href="#cb9-11"></a>  <span class="kw">dir.create</span>(<span class="st">&quot;~/data/OISST&quot;</span>, <span class="dt">showWarnings =</span> F)</span>
<span id="cb9-12"><a href="#cb9-12"></a>  file_name &lt;-<span class="st"> </span><span class="kw">paste0</span>(<span class="st">&quot;~/data/OISST/&quot;</span>,<span class="kw">sapply</span>(<span class="kw">strsplit</span>(target_URL, <span class="dt">split =</span> <span class="st">&quot;/&quot;</span>), <span class="st">&quot;[[&quot;</span>, <span class="dv">10</span>))</span>
<span id="cb9-13"><a href="#cb9-13"></a>  <span class="cf">if</span>(<span class="op">!</span><span class="kw">file.exists</span>(file_name)) <span class="kw">download.file</span>(<span class="dt">url =</span> target_URL, <span class="dt">method =</span> <span class="st">&quot;libcurl&quot;</span>, <span class="dt">destfile =</span> file_name)</span>
<span id="cb9-14"><a href="#cb9-14"></a>}</span>
<span id="cb9-15"><a href="#cb9-15"></a></span>
<span id="cb9-16"><a href="#cb9-16"></a><span class="co"># The more cores used, the faster the data may be downloaded</span></span>
<span id="cb9-17"><a href="#cb9-17"></a>  <span class="co"># It is best practice to not use all of the cores on one&#39;s machine</span></span>
<span id="cb9-18"><a href="#cb9-18"></a>  <span class="co"># The laptop on which I am running this code has 8 cores, so I use 7 here</span></span>
<span id="cb9-19"><a href="#cb9-19"></a>doParallel<span class="op">::</span><span class="kw">registerDoParallel</span>(<span class="dt">cores =</span> <span class="dv">7</span>)</span>
<span id="cb9-20"><a href="#cb9-20"></a></span>
<span id="cb9-21"><a href="#cb9-21"></a><span class="co"># And with that we are clear for take off</span></span>
<span id="cb9-22"><a href="#cb9-22"></a><span class="kw">system.time</span>(plyr<span class="op">::</span><span class="kw">l_ply</span>(OISST_files<span class="op">$</span>file_name, <span class="dt">.fun =</span> OISST_url_daily_dl, <span class="dt">.parallel =</span> T)) <span class="co"># ~15 seconds</span></span>
<span id="cb9-23"><a href="#cb9-23"></a></span>
<span id="cb9-24"><a href="#cb9-24"></a><span class="co"># In roughly 15 seconds a user may have a full month of global data downloaded</span></span>
<span id="cb9-25"><a href="#cb9-25"></a><span class="co"># This scales well into years and decades, and is much faster with more cores</span></span>
<span id="cb9-26"><a href="#cb9-26"></a><span class="co"># Download speeds will also depend on the speed of the users internet connection</span></span></code></pre></div>
</div>
<div id="load-data" class="section level3">
<h3>Load data</h3>
<p>The following code chunk contains the function we may use to load and prepare our OISST data for further use in R.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1"></a><span class="co"># This function will load and subset daily data into one data.frame</span></span>
<span id="cb10-2"><a href="#cb10-2"></a><span class="co"># Note that the subsetting by lon/lat is done before the data are loaded</span></span>
<span id="cb10-3"><a href="#cb10-3"></a>  <span class="co"># This means it will use much less RAM and is viable for use on most laptops</span></span>
<span id="cb10-4"><a href="#cb10-4"></a>  <span class="co"># Assuming one&#39;s study area is not too large</span></span>
<span id="cb10-5"><a href="#cb10-5"></a>OISST_load &lt;-<span class="st"> </span><span class="cf">function</span>(file_name, lon1, lon2, lat1, lat2){</span>
<span id="cb10-6"><a href="#cb10-6"></a>      OISST_dat &lt;-<span class="st"> </span><span class="kw">tidync</span>(file_name) <span class="op">%&gt;%</span></span>
<span id="cb10-7"><a href="#cb10-7"></a><span class="st">        </span><span class="kw">hyper_filter</span>(<span class="dt">lon =</span> <span class="kw">between</span>(lon, lon1, lon2),</span>
<span id="cb10-8"><a href="#cb10-8"></a>                     <span class="dt">lat =</span> <span class="kw">between</span>(lat, lat1, lat2)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb10-9"><a href="#cb10-9"></a><span class="st">        </span><span class="kw">hyper_tibble</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb10-10"><a href="#cb10-10"></a><span class="st">        </span><span class="kw">select</span>(lon, lat, time, sst) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb10-11"><a href="#cb10-11"></a><span class="st">        </span>dplyr<span class="op">::</span><span class="kw">rename</span>(<span class="dt">t =</span> time, <span class="dt">temp =</span> sst) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb10-12"><a href="#cb10-12"></a><span class="st">        </span><span class="kw">mutate</span>(<span class="dt">t =</span> <span class="kw">as.Date</span>(t, <span class="dt">origin =</span> <span class="st">&quot;1978-01-01&quot;</span>))</span>
<span id="cb10-13"><a href="#cb10-13"></a>      <span class="kw">return</span>(OISST_dat)</span>
<span id="cb10-14"><a href="#cb10-14"></a>}</span>
<span id="cb10-15"><a href="#cb10-15"></a></span>
<span id="cb10-16"><a href="#cb10-16"></a><span class="co"># Locate the files that will be loaded</span></span>
<span id="cb10-17"><a href="#cb10-17"></a>OISST_files &lt;-<span class="st"> </span><span class="kw">dir</span>(<span class="st">&quot;~/data/OISST&quot;</span>, <span class="dt">full.names =</span> T)</span>
<span id="cb10-18"><a href="#cb10-18"></a></span>
<span id="cb10-19"><a href="#cb10-19"></a><span class="co"># Load the data in parallel</span></span>
<span id="cb10-20"><a href="#cb10-20"></a>OISST_dat &lt;-<span class="st"> </span>plyr<span class="op">::</span><span class="kw">ldply</span>(<span class="dt">.data =</span> OISST_files, <span class="dt">.fun =</span> OISST_load, <span class="dt">.parallel =</span> T,</span>
<span id="cb10-21"><a href="#cb10-21"></a>                         <span class="dt">lon1 =</span> <span class="dv">270</span>, <span class="dt">lon2 =</span> <span class="dv">320</span>, <span class="dt">lat1 =</span> <span class="dv">30</span>, <span class="dt">lat2 =</span> <span class="dv">50</span>)</span>
<span id="cb10-22"><a href="#cb10-22"></a></span>
<span id="cb10-23"><a href="#cb10-23"></a><span class="co"># It should only take a few seconds to load one month of data depending on the size of the lon/lat extent chosen</span></span></code></pre></div>
<p>In the code chunk above I have chosen the spatial extent of longitude 270 to 320 and latitude 30 to 50. This a window over the Atlantic Coast of North America. One may simply change the lon/lat values above as necessary to match the desired study area. The function also re-labels the â€˜timeâ€™ column as â€˜tâ€™, and the â€˜sstâ€™ column as â€˜tempâ€™. We do this now so that they match the default column names that are expected for calculating MHWs so we wonâ€™t have to do any extra work later on.</p>
<p>Again, please note that trying to load too much data at once may be too much for the RAM on oneâ€™s machine. If running the above code causes oneâ€™s machine to hang, try loading a smaller subset of data. Or make friends with someone with a server sized machine.</p>
</div>
<div id="visualise-data-1" class="section level3">
<h3>Visualise data</h3>
<p>It is always good to visualise data early and often in any workflow. The code pipeline below shows how we can visualise a day of data from those weâ€™ve loaded.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1"></a>OISST_dat <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb11-2"><a href="#cb11-2"></a><span class="st">  </span><span class="kw">filter</span>(t <span class="op">==</span><span class="st"> &quot;2019-12-01&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb11-3"><a href="#cb11-3"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> lon, <span class="dt">y =</span> lat)) <span class="op">+</span></span>
<span id="cb11-4"><a href="#cb11-4"></a><span class="st">  </span><span class="kw">geom_tile</span>(<span class="kw">aes</span>(<span class="dt">fill =</span> temp)) <span class="op">+</span></span>
<span id="cb11-5"><a href="#cb11-5"></a><span class="st">  </span><span class="kw">scale_fill_viridis_c</span>() <span class="op">+</span></span>
<span id="cb11-6"><a href="#cb11-6"></a><span class="st">  </span><span class="kw">coord_quickmap</span>(<span class="dt">expand =</span> F) <span class="op">+</span></span>
<span id="cb11-7"><a href="#cb11-7"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="ot">NULL</span>, <span class="dt">y =</span> <span class="ot">NULL</span>, <span class="dt">fill =</span> <span class="st">&quot;SST (Â°C)&quot;</span>) <span class="op">+</span></span>
<span id="cb11-8"><a href="#cb11-8"></a><span class="st">  </span><span class="kw">theme</span>(<span class="dt">legend.position =</span> <span class="st">&quot;bottom&quot;</span>)</span></code></pre></div>
<p>In the next vignette we will see how to <a href="https://robwschlegel.github.io/heatwaveR/articles/gridded_event_detection.html">detect MHWs in gridded data</a>.</p>
</div>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
